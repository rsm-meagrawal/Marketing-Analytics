[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "This is Project 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning\n\n\n\n\n\n\nMegha Agrawal\n\n\nJun 11, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nMegha Agrawal\n\n\nJun 11, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\n\n\nMegha Agrawal\n\n\nInvalid Date\n\n\n\n\n\n\n\n\n\n\n\n\nMultinomial Logit Model\n\n\n\n\n\n\nMegha Agrawal\n\n\nInvalid Date\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis of Cars\n\n\n\n\n\n\nMegha Agrawal\n\n\nJun 11, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/project4/hw2_questions.html",
    "href": "blog/project4/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\n\n\nData\n\n\n\n\n\n\n# Read in the data\ndata &lt;- read.csv(\"/Users/megha/Desktop/Marketing Analytics/mysite/blog/project4/blueprinty.csv\")\nhead(data)\n\n  patents    region  age iscustomer\n1       0   Midwest 32.5          0\n2       3 Southwest 37.5          0\n3       4 Northwest 27.0          1\n4       3 Northeast 24.5          0\n5       3 Southwest 37.0          0\n6       6 Northeast 29.5          1\n\n\n\n\n\n\n\nShow Code\n# Load libraries\nlibrary(ggplot2)\nlibrary(dplyr)\n# Transform iscustomer to a factor for clarity\ndata$iscustomer &lt;- factor(data$iscustomer, labels = c(\"Non-Customer\", \"Customer\"))\n\n# Plot histograms with pretty formatting\nggplot(data, aes(x = patents, fill = iscustomer)) +\n  geom_histogram(binwidth = 1, alpha = 0.7, position = 'identity', color = \"black\") +\n  facet_wrap(~iscustomer) +\n  labs(title = \"Histogram of Patents by Customer Status\",\n       x = \"Number of Patents\",\n       y = \"Frequency\") +\n  theme_minimal(base_size = 14) +\n  theme(legend.position = \"none\") +\n  scale_fill_manual(values = c(\"lightblue\", \"lightgreen\"))\n\n\n\n\n\n\n\n\n\nThe histogram compares the distribution of the number of patents held by customers versus non-customers:\n\nNon-Customers: The patent count is predominantly concentrated around lower values (0-5 patents), indicating most non-customers possess fewer patents.\nCustomers: Patents held by customers show a slightly broader distribution, extending toward higher patent counts, with a higher mean overall compared to non-customers.\n\nThis suggests that customers generally tend to hold more patents than non-customers, implying a potential link between customer status and innovation or patent activity.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n\nShow Code\n# Convert customer status into factor for clear labeling\ndata$iscustomer &lt;- factor(data$iscustomer, labels = c(\"Non-Customer\", \"Customer\"))\n\n# Age Distribution Boxplot\nggplot(data, aes(x = iscustomer, y = age, fill = iscustomer)) +\n  geom_boxplot(alpha = 0.7) +\n  labs(title = \"Age Distribution by Customer Status\",\n       x = \"Customer Status\",\n       y = \"Age\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  scale_fill_manual(values = c(\"lightblue\", \"lightgreen\"))\n\n\n\n\n\n\n\n\n\nShow Code\n# Region Distribution Barplot\ndata %&gt;%\n  group_by(region, iscustomer) %&gt;%\n  summarise(count = n()) %&gt;%\n  group_by(iscustomer) %&gt;%\n  mutate(percentage = count / sum(count) * 100) %&gt;%\n  ggplot(aes(x = region, y = percentage, fill = iscustomer)) +\n  geom_bar(stat = \"identity\", position = position_dodge()) +\n  labs(title = \"Region Distribution by Customer Status\",\n       x = \"Region\",\n       y = \"Percentage (%)\",\n       fill = \"Customer Status\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"orange\", \"tomato\")) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nAge Distribution: Both customer groups (customers and non-customers) show similar median ages. Customers have slightly less variation in age, with fewer extreme outliers, suggesting that age alone does not significantly differentiate customers from non-customers.\nRegion Distribution: There’s a clear regional difference between customers and non-customers: Customers are heavily concentrated in the Northeast region. Non-customers are more evenly distributed across regions, with a notable presence in the Southwest.\nThis suggests region might play a significant role in customer status, particularly with a strong customer base in the Northeast.\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood. Let \\(Y_1, Y_2, \\dots, Y_n \\overset{iid}{\\sim} \\text{Poisson}(\\lambda)\\). The probability mass function for each observation is:\n\\[\nf(Y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nThen, the likelihood function for the entire sample is:\n\\[\n\\mathcal{L}(\\lambda \\mid Y_1, \\dots, Y_n) = \\prod_{i=1}^n \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n= e^{-n\\lambda} \\lambda^{\\sum_{i=1}^n Y_i} \\prod_{i=1}^n \\frac{1}{Y_i!}\n\\]\nOr, more compactly:\n\\[\n\\mathcal{L}(\\lambda \\mid \\mathbf{Y}) = e^{-n\\lambda} \\lambda^{\\sum Y_i} \\prod_{i=1}^n \\frac{1}{Y_i!}\n\\]\n\n# Poisson likelihood function\npoisson_likelihood &lt;- function(lambda, Y) {\n  likelihood &lt;- prod(exp(-lambda) * lambda^Y / factorial(Y))\n  return(likelihood)\n}\n\n# Poisson log-likelihood function\npoisson_loglikelihood &lt;- function(lambda, Y) {\n  loglikelihood &lt;- sum(-lambda + Y * log(lambda) - lgamma(Y + 1))\n  return(loglikelihood)\n}\n\n\n\nShow Code\n# Observed patents\nY &lt;- data$patents\n\n# Define the Poisson log-likelihood function\npoisson_loglikelihood &lt;- function(lambda, Y) {\n  sum(-lambda + Y * log(lambda) - lgamma(Y + 1))\n}\n\n# Range of lambda values\nlambda_values &lt;- seq(0.1, 10, length.out = 100)\n\n# Compute log-likelihood for each lambda\nloglik_values &lt;- sapply(lambda_values, poisson_loglikelihood, Y = Y)\n\n# Create a data frame for plotting\nplot_data &lt;- data.frame(lambda = lambda_values, loglikelihood = loglik_values)\n\n# Plot lambda vs. log-likelihood\nggplot(plot_data, aes(x = lambda, y = loglikelihood)) +\n  geom_line(color = \"blue\", linewidth = 1) +\n  labs(title = \"Poisson Log-Likelihood across Lambda Values\",\n       x = expression(lambda),\n       y = \"Log-Likelihood\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep 1: Write down the log-likelihood\nGiven ( Y_i () ):\n\\[\n\\ell(\\lambda|Y) = \\sum_{i=1}^{n} \\left(-\\lambda + Y_i \\log(\\lambda) - \\log(Y_i!)\\right)\n\\]\n\nStep 2: Take the first derivative of the log-likelihood\nDifferentiate ((|Y)) with respect to ():\n\\[\n\\frac{d\\ell(\\lambda|Y)}{d\\lambda} = \\sum_{i=1}^{n}\\left(-1 + \\frac{Y_i}{\\lambda}\\right)\n= -n + \\frac{\\sum_{i=1}^{n}Y_i}{\\lambda}\n\\]\n\nStep 3: Set the derivative equal to zero and solve for ()\n\\[\n-n + \\frac{\\sum_{i=1}^{n}Y_i}{\\lambda} = 0\n\\]\nSolve for ():\n\\[\n\\frac{\\sum_{i=1}^{n}Y_i}{\\lambda} = n \\quad \\Rightarrow \\quad \\lambda_{MLE} = \\frac{\\sum_{i=1}^{n}Y_i}{n} = \\bar{Y}\n\\]\n\nConclusion:\nThe Maximum Likelihood Estimator (MLE) for () is the sample mean ({Y}), which intuitively matches our expectations from the Poisson distribution since ( E[Y] = ):\n\\[\n\\boxed{\\lambda_{MLE} = \\bar{Y}}\n\\]\n\n# Negative log-likelihood function\nneg_loglikelihood &lt;- function(lambda, Y) {\n  -sum(-lambda + Y * log(lambda) - lgamma(Y + 1))\n}\n\n# Find lambda MLE using optim()\nresult &lt;- optim(par = 1, fn = neg_loglikelihood, Y = Y, method = \"L-BFGS-B\", lower = 0.0001)\n\n# Extract MLE estimate\nlambda_mle &lt;- result$par\nlambda_mle\n\n[1] 3.684667\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\\[\n\\ell(\\beta|Y,X) = \\sum_{i=1}^{n}\\left[-e^{X_i'\\beta} + Y_i(X_i'\\beta) - \\log(Y_i!)\\right]\n\\]\n\n\nShow Code\n# Construct X matrix with intercept, age, age squared, regions (dummy variables), and iscustomer\nX &lt;- model.matrix(~ age + I(age^2) + region + iscustomer, data = data)\n\n# Response variable\nY &lt;- data$patents\n\n# Negative log-likelihood function for Poisson regression\nneg_loglik_poisson_reg &lt;- function(beta, Y, X){\n  lambda &lt;- exp(X %*% beta)\n  -sum(-lambda + Y * log(lambda) - lgamma(Y + 1))\n}\n\n# Initial beta values\ninitial_beta &lt;- rep(0, ncol(X))\n\n# Find MLE using optim()\nresult &lt;- optim(initial_beta, \n                neg_loglik_poisson_reg, \n                Y = Y, \n                X = X,\n                method = \"BFGS\",\n                hessian = TRUE)\n\n# Extract estimates\nbeta_mle &lt;- result$par\n# Calculate standard errors from Hessian\nse_beta &lt;- sqrt(diag(solve(result$hessian)))\n\n# Output results table\nresults_table &lt;- data.frame(\n  Coefficient = beta_mle,\n  Std_Error = se_beta,\n  row.names = colnames(X)\n)\n\nprint(results_table)\n\n\n                    Coefficient    Std_Error\n(Intercept)        -0.125735915 0.1122180354\nage                 0.115793715 0.0063574230\nI(age^2)           -0.002228748 0.0000771291\nregionNortheast    -0.024556782 0.0433762879\nregionNorthwest    -0.034827790 0.0529311002\nregionSouth        -0.005441860 0.0524007440\nregionSouthwest    -0.037784109 0.0471722463\niscustomerCustomer  0.060665584 0.0320588299\n\n\n\n\nShow Code\n# Fit the Poisson regression model\npoisson_model &lt;- glm(patents ~ age + I(age^2) + region + iscustomer, \n                     family = poisson(link = \"log\"), \n                     data = data)\n\n# Summarize the results\nsummary(poisson_model)\n\n\n\nCall:\nglm(formula = patents ~ age + I(age^2) + region + iscustomer, \n    family = poisson(link = \"log\"), data = data)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)        -0.508920   0.183179  -2.778  0.00546 ** \nage                 0.148619   0.013869  10.716  &lt; 2e-16 ***\nI(age^2)           -0.002971   0.000258 -11.513  &lt; 2e-16 ***\nregionNortheast     0.029170   0.043625   0.669  0.50372    \nregionNorthwest    -0.017574   0.053781  -0.327  0.74383    \nregionSouth         0.056561   0.052662   1.074  0.28281    \nregionSouthwest     0.050576   0.047198   1.072  0.28391    \niscustomerCustomer  0.207591   0.030895   6.719 1.83e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 2362.5  on 1499  degrees of freedom\nResidual deviance: 2143.3  on 1492  degrees of freedom\nAIC: 6532.1\n\nNumber of Fisher Scoring iterations: 5\n\n\n\nIntercept: Baseline log count of patents when all covariates are zero.\nAge: Positive coefficient implies older firms tend to have higher patent counts.\nAge squared: Negative coefficient indicates diminishing returns with age—patent count increases initially and decreases for very old firms.\nRegion: Coefficients represent differences in patent counts relative to the reference region.\nCustomer Status (iscustomer): Positive and significant coefficient indicates customers of Blueprinty typically have more patents.\n\nUse exp(coef(poisson_model)) to clearly interpret coefficients as multiplicative changes in patent rates.\n\n\n\nThe average predicted increase in the number of patents attributable specifically to being a Blueprinty customer is approximately 0.79 patents per firm.\nThis indicates that firms using Blueprinty’s software can expect, on average, nearly one additional patent compared to non-customer firms.\nThis effect is both statistically significant (as previously established from regression results) and practically meaningful, clearly highlighting the positive impact of Blueprinty’s software on patent success."
  },
  {
    "objectID": "blog/project4/hw2_questions.html#blueprinty-case-study",
    "href": "blog/project4/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\n\n\nData\n\n\n\n\n\n\n# Read in the data\ndata &lt;- read.csv(\"/Users/megha/Desktop/Marketing Analytics/mysite/blog/project4/blueprinty.csv\")\nhead(data)\n\n  patents    region  age iscustomer\n1       0   Midwest 32.5          0\n2       3 Southwest 37.5          0\n3       4 Northwest 27.0          1\n4       3 Northeast 24.5          0\n5       3 Southwest 37.0          0\n6       6 Northeast 29.5          1\n\n\n\n\n\n\n\nShow Code\n# Load libraries\nlibrary(ggplot2)\nlibrary(dplyr)\n# Transform iscustomer to a factor for clarity\ndata$iscustomer &lt;- factor(data$iscustomer, labels = c(\"Non-Customer\", \"Customer\"))\n\n# Plot histograms with pretty formatting\nggplot(data, aes(x = patents, fill = iscustomer)) +\n  geom_histogram(binwidth = 1, alpha = 0.7, position = 'identity', color = \"black\") +\n  facet_wrap(~iscustomer) +\n  labs(title = \"Histogram of Patents by Customer Status\",\n       x = \"Number of Patents\",\n       y = \"Frequency\") +\n  theme_minimal(base_size = 14) +\n  theme(legend.position = \"none\") +\n  scale_fill_manual(values = c(\"lightblue\", \"lightgreen\"))\n\n\n\n\n\n\n\n\n\nThe histogram compares the distribution of the number of patents held by customers versus non-customers:\n\nNon-Customers: The patent count is predominantly concentrated around lower values (0-5 patents), indicating most non-customers possess fewer patents.\nCustomers: Patents held by customers show a slightly broader distribution, extending toward higher patent counts, with a higher mean overall compared to non-customers.\n\nThis suggests that customers generally tend to hold more patents than non-customers, implying a potential link between customer status and innovation or patent activity.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n\nShow Code\n# Convert customer status into factor for clear labeling\ndata$iscustomer &lt;- factor(data$iscustomer, labels = c(\"Non-Customer\", \"Customer\"))\n\n# Age Distribution Boxplot\nggplot(data, aes(x = iscustomer, y = age, fill = iscustomer)) +\n  geom_boxplot(alpha = 0.7) +\n  labs(title = \"Age Distribution by Customer Status\",\n       x = \"Customer Status\",\n       y = \"Age\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  scale_fill_manual(values = c(\"lightblue\", \"lightgreen\"))\n\n\n\n\n\n\n\n\n\nShow Code\n# Region Distribution Barplot\ndata %&gt;%\n  group_by(region, iscustomer) %&gt;%\n  summarise(count = n()) %&gt;%\n  group_by(iscustomer) %&gt;%\n  mutate(percentage = count / sum(count) * 100) %&gt;%\n  ggplot(aes(x = region, y = percentage, fill = iscustomer)) +\n  geom_bar(stat = \"identity\", position = position_dodge()) +\n  labs(title = \"Region Distribution by Customer Status\",\n       x = \"Region\",\n       y = \"Percentage (%)\",\n       fill = \"Customer Status\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"orange\", \"tomato\")) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nAge Distribution: Both customer groups (customers and non-customers) show similar median ages. Customers have slightly less variation in age, with fewer extreme outliers, suggesting that age alone does not significantly differentiate customers from non-customers.\nRegion Distribution: There’s a clear regional difference between customers and non-customers: Customers are heavily concentrated in the Northeast region. Non-customers are more evenly distributed across regions, with a notable presence in the Southwest.\nThis suggests region might play a significant role in customer status, particularly with a strong customer base in the Northeast.\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood. Let \\(Y_1, Y_2, \\dots, Y_n \\overset{iid}{\\sim} \\text{Poisson}(\\lambda)\\). The probability mass function for each observation is:\n\\[\nf(Y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nThen, the likelihood function for the entire sample is:\n\\[\n\\mathcal{L}(\\lambda \\mid Y_1, \\dots, Y_n) = \\prod_{i=1}^n \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n= e^{-n\\lambda} \\lambda^{\\sum_{i=1}^n Y_i} \\prod_{i=1}^n \\frac{1}{Y_i!}\n\\]\nOr, more compactly:\n\\[\n\\mathcal{L}(\\lambda \\mid \\mathbf{Y}) = e^{-n\\lambda} \\lambda^{\\sum Y_i} \\prod_{i=1}^n \\frac{1}{Y_i!}\n\\]\n\n# Poisson likelihood function\npoisson_likelihood &lt;- function(lambda, Y) {\n  likelihood &lt;- prod(exp(-lambda) * lambda^Y / factorial(Y))\n  return(likelihood)\n}\n\n# Poisson log-likelihood function\npoisson_loglikelihood &lt;- function(lambda, Y) {\n  loglikelihood &lt;- sum(-lambda + Y * log(lambda) - lgamma(Y + 1))\n  return(loglikelihood)\n}\n\n\n\nShow Code\n# Observed patents\nY &lt;- data$patents\n\n# Define the Poisson log-likelihood function\npoisson_loglikelihood &lt;- function(lambda, Y) {\n  sum(-lambda + Y * log(lambda) - lgamma(Y + 1))\n}\n\n# Range of lambda values\nlambda_values &lt;- seq(0.1, 10, length.out = 100)\n\n# Compute log-likelihood for each lambda\nloglik_values &lt;- sapply(lambda_values, poisson_loglikelihood, Y = Y)\n\n# Create a data frame for plotting\nplot_data &lt;- data.frame(lambda = lambda_values, loglikelihood = loglik_values)\n\n# Plot lambda vs. log-likelihood\nggplot(plot_data, aes(x = lambda, y = loglikelihood)) +\n  geom_line(color = \"blue\", linewidth = 1) +\n  labs(title = \"Poisson Log-Likelihood across Lambda Values\",\n       x = expression(lambda),\n       y = \"Log-Likelihood\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep 1: Write down the log-likelihood\nGiven ( Y_i () ):\n\\[\n\\ell(\\lambda|Y) = \\sum_{i=1}^{n} \\left(-\\lambda + Y_i \\log(\\lambda) - \\log(Y_i!)\\right)\n\\]\n\nStep 2: Take the first derivative of the log-likelihood\nDifferentiate ((|Y)) with respect to ():\n\\[\n\\frac{d\\ell(\\lambda|Y)}{d\\lambda} = \\sum_{i=1}^{n}\\left(-1 + \\frac{Y_i}{\\lambda}\\right)\n= -n + \\frac{\\sum_{i=1}^{n}Y_i}{\\lambda}\n\\]\n\nStep 3: Set the derivative equal to zero and solve for ()\n\\[\n-n + \\frac{\\sum_{i=1}^{n}Y_i}{\\lambda} = 0\n\\]\nSolve for ():\n\\[\n\\frac{\\sum_{i=1}^{n}Y_i}{\\lambda} = n \\quad \\Rightarrow \\quad \\lambda_{MLE} = \\frac{\\sum_{i=1}^{n}Y_i}{n} = \\bar{Y}\n\\]\n\nConclusion:\nThe Maximum Likelihood Estimator (MLE) for () is the sample mean ({Y}), which intuitively matches our expectations from the Poisson distribution since ( E[Y] = ):\n\\[\n\\boxed{\\lambda_{MLE} = \\bar{Y}}\n\\]\n\n# Negative log-likelihood function\nneg_loglikelihood &lt;- function(lambda, Y) {\n  -sum(-lambda + Y * log(lambda) - lgamma(Y + 1))\n}\n\n# Find lambda MLE using optim()\nresult &lt;- optim(par = 1, fn = neg_loglikelihood, Y = Y, method = \"L-BFGS-B\", lower = 0.0001)\n\n# Extract MLE estimate\nlambda_mle &lt;- result$par\nlambda_mle\n\n[1] 3.684667\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\\[\n\\ell(\\beta|Y,X) = \\sum_{i=1}^{n}\\left[-e^{X_i'\\beta} + Y_i(X_i'\\beta) - \\log(Y_i!)\\right]\n\\]\n\n\nShow Code\n# Construct X matrix with intercept, age, age squared, regions (dummy variables), and iscustomer\nX &lt;- model.matrix(~ age + I(age^2) + region + iscustomer, data = data)\n\n# Response variable\nY &lt;- data$patents\n\n# Negative log-likelihood function for Poisson regression\nneg_loglik_poisson_reg &lt;- function(beta, Y, X){\n  lambda &lt;- exp(X %*% beta)\n  -sum(-lambda + Y * log(lambda) - lgamma(Y + 1))\n}\n\n# Initial beta values\ninitial_beta &lt;- rep(0, ncol(X))\n\n# Find MLE using optim()\nresult &lt;- optim(initial_beta, \n                neg_loglik_poisson_reg, \n                Y = Y, \n                X = X,\n                method = \"BFGS\",\n                hessian = TRUE)\n\n# Extract estimates\nbeta_mle &lt;- result$par\n# Calculate standard errors from Hessian\nse_beta &lt;- sqrt(diag(solve(result$hessian)))\n\n# Output results table\nresults_table &lt;- data.frame(\n  Coefficient = beta_mle,\n  Std_Error = se_beta,\n  row.names = colnames(X)\n)\n\nprint(results_table)\n\n\n                    Coefficient    Std_Error\n(Intercept)        -0.125735915 0.1122180354\nage                 0.115793715 0.0063574230\nI(age^2)           -0.002228748 0.0000771291\nregionNortheast    -0.024556782 0.0433762879\nregionNorthwest    -0.034827790 0.0529311002\nregionSouth        -0.005441860 0.0524007440\nregionSouthwest    -0.037784109 0.0471722463\niscustomerCustomer  0.060665584 0.0320588299\n\n\n\n\nShow Code\n# Fit the Poisson regression model\npoisson_model &lt;- glm(patents ~ age + I(age^2) + region + iscustomer, \n                     family = poisson(link = \"log\"), \n                     data = data)\n\n# Summarize the results\nsummary(poisson_model)\n\n\n\nCall:\nglm(formula = patents ~ age + I(age^2) + region + iscustomer, \n    family = poisson(link = \"log\"), data = data)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)        -0.508920   0.183179  -2.778  0.00546 ** \nage                 0.148619   0.013869  10.716  &lt; 2e-16 ***\nI(age^2)           -0.002971   0.000258 -11.513  &lt; 2e-16 ***\nregionNortheast     0.029170   0.043625   0.669  0.50372    \nregionNorthwest    -0.017574   0.053781  -0.327  0.74383    \nregionSouth         0.056561   0.052662   1.074  0.28281    \nregionSouthwest     0.050576   0.047198   1.072  0.28391    \niscustomerCustomer  0.207591   0.030895   6.719 1.83e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 2362.5  on 1499  degrees of freedom\nResidual deviance: 2143.3  on 1492  degrees of freedom\nAIC: 6532.1\n\nNumber of Fisher Scoring iterations: 5\n\n\n\nIntercept: Baseline log count of patents when all covariates are zero.\nAge: Positive coefficient implies older firms tend to have higher patent counts.\nAge squared: Negative coefficient indicates diminishing returns with age—patent count increases initially and decreases for very old firms.\nRegion: Coefficients represent differences in patent counts relative to the reference region.\nCustomer Status (iscustomer): Positive and significant coefficient indicates customers of Blueprinty typically have more patents.\n\nUse exp(coef(poisson_model)) to clearly interpret coefficients as multiplicative changes in patent rates.\n\n\n\nThe average predicted increase in the number of patents attributable specifically to being a Blueprinty customer is approximately 0.79 patents per firm.\nThis indicates that firms using Blueprinty’s software can expect, on average, nearly one additional patent compared to non-customer firms.\nThis effect is both statistically significant (as previously established from regression results) and practically meaningful, clearly highlighting the positive impact of Blueprinty’s software on patent success."
  },
  {
    "objectID": "blog/project4/hw2_questions.html#airbnb-case-study",
    "href": "blog/project4/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\n\n# Load data\nairbnb &lt;- read.csv(\"/Users/megha/Desktop/Marketing Analytics/mysite/blog/project4/airbnb.csv\")\n\n# Remove rows with missing values on relevant variables\nairbnb_clean &lt;- airbnb %&gt;%\n  filter(\n    !is.na(bathrooms),\n    !is.na(bedrooms),\n    !is.na(review_scores_cleanliness),\n    !is.na(review_scores_location),\n    !is.na(review_scores_value)\n  )\n\n\n\nShow Code\nlibrary(ggplot2)\n\n# Histogram of number_of_reviews\nggplot(airbnb_clean, aes(x=number_of_reviews)) +\n  geom_histogram(fill='lightblue', color='black', bins=30) +\n  theme_minimal() +\n  labs(title=\"Distribution of Number of Reviews (Bookings Proxy)\", \n       x=\"Number of Reviews\", y=\"Count\")\n\n\n\n\n\n\n\n\n\n\n\nShow Code\n# Load necessary libraries\nlibrary(knitr)\n\n# Compute correlations clearly\ncorrelations &lt;- cor(airbnb_clean[, c(\"days\", \"bathrooms\", \"bedrooms\", \"price\",\n                                     \"review_scores_cleanliness\",\n                                     \"review_scores_location\",\n                                     \"review_scores_value\",\n                                     \"number_of_reviews\")], \n                    use = \"complete.obs\")\n\n# Present correlations as a pretty markdown table\nkable(correlations, digits = 3, format = \"markdown\",\n      caption = \"Correlation Matrix for Airbnb Numerical Variables\")\n\n\n\nCorrelation Matrix for Airbnb Numerical Variables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndays\nbathrooms\nbedrooms\nprice\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\nnumber_of_reviews\n\n\n\n\ndays\n1.000\n-0.015\n0.005\n0.019\n0.008\n0.009\n0.000\n0.115\n\n\nbathrooms\n-0.015\n1.000\n0.408\n0.253\n0.003\n-0.030\n0.009\n-0.014\n\n\nbedrooms\n0.005\n0.408\n1.000\n0.292\n0.003\n-0.049\n-0.013\n0.027\n\n\nprice\n0.019\n0.253\n0.292\n1.000\n0.029\n0.099\n0.002\n-0.002\n\n\nreview_scores_cleanliness\n0.008\n0.003\n0.003\n0.029\n1.000\n0.327\n0.615\n0.029\n\n\nreview_scores_location\n0.009\n-0.030\n-0.049\n0.099\n0.327\n1.000\n0.448\n-0.050\n\n\nreview_scores_value\n0.000\n0.009\n-0.013\n0.002\n0.615\n0.448\n1.000\n-0.032\n\n\nnumber_of_reviews\n0.115\n-0.014\n0.027\n-0.002\n0.029\n-0.050\n-0.032\n1.000\n\n\n\n\n\n\n\nShow Code\n# Fit Poisson regression model\n# Load required packages\nlibrary(broom)\nlibrary(knitr)\nlibrary(dplyr)\n\n# Fit Poisson regression model (repeat if necessary)\nmodel &lt;- glm(number_of_reviews ~ days + bathrooms + bedrooms + price +\n               review_scores_cleanliness + review_scores_location +\n               review_scores_value + room_type + instant_bookable,\n             family = poisson(link = \"log\"),\n             data = airbnb_clean)\n\n# Make pretty regression output\nmodel_summary &lt;- tidy(model) %&gt;%\n  mutate(significance = case_when(\n    p.value &lt; 0.001 ~ \"***\",\n    p.value &lt; 0.01 ~ \"**\",\n    p.value &lt; 0.05 ~ \"*\",\n    p.value &lt; 0.1 ~ \".\",\n    TRUE ~ \"\"\n  ))\n\n# Present as a formatted markdown table\nkable(model_summary, digits = 4, format = \"markdown\",\n      col.names = c(\"Variable\", \"Estimate\", \"Std. Error\", \"z-value\", \"p-value\", \"Significance\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nEstimate\nStd. Error\nz-value\np-value\nSignificance\n\n\n\n\n(Intercept)\n3.4980\n0.0161\n217.3963\n0.0000\n***\n\n\ndays\n0.0001\n0.0000\n129.7567\n0.0000\n***\n\n\nbathrooms\n-0.1177\n0.0037\n-31.3942\n0.0000\n***\n\n\nbedrooms\n0.0741\n0.0020\n37.1972\n0.0000\n***\n\n\nprice\n0.0000\n0.0000\n-2.1509\n0.0315\n*\n\n\nreview_scores_cleanliness\n0.1131\n0.0015\n75.6106\n0.0000\n***\n\n\nreview_scores_location\n-0.0769\n0.0016\n-47.7962\n0.0000\n***\n\n\nreview_scores_value\n-0.0911\n0.0018\n-50.4899\n0.0000\n***\n\n\nroom_typePrivate room\n-0.0105\n0.0027\n-3.8475\n0.0001\n***\n\n\nroom_typeShared room\n-0.2463\n0.0086\n-28.5781\n0.0000\n***\n\n\ninstant_bookablet\n0.3459\n0.0029\n119.6656\n0.0000\n***\n\n\n\n\n\n\n\nConclusion\n\nNumber of reviews is positively correlated with the number of days listed. Units listed longer accumulate more reviews (proxy for bookings).\nPrice has a slight negative correlation with the number of reviews. Higher-priced units tend to have fewer bookings.\nBedrooms and bathrooms show moderate correlations with reviews, indicating larger properties generally attract more bookings, although bathrooms’ impact is nuanced.\nReview scores (cleanliness, location, and value) are significantly correlated among themselves, implying consistency in review quality, but their correlation with bookings is moderate, indicating reviews alone don’t fully determine bookings.\nDays listed correlates slightly positively with property attributes (bedrooms, bathrooms), implying established properties often offer greater amenities."
  },
  {
    "objectID": "blog/project1/index.html",
    "href": "blog/project1/index.html",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data\n\n\n\nI analyzed the data"
  },
  {
    "objectID": "blog/project1/index.html#section-1-data",
    "href": "blog/project1/index.html#section-1-data",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data"
  },
  {
    "objectID": "blog/project1/index.html#section-2-analysis",
    "href": "blog/project1/index.html#section-2-analysis",
    "title": "This is Project 1",
    "section": "",
    "text": "I analyzed the data"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Here is my resume! Download PDF file."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Megha Agrawal",
    "section": "",
    "text": "Hey, I’m Megha Agrawal pursuing Master’s in Business Analytics at Rady School of Management."
  },
  {
    "objectID": "blog/project3/index.html",
    "href": "blog/project3/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/project3/index.html#introduction",
    "href": "blog/project3/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/project3/index.html#data",
    "href": "blog/project3/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nlibrary(haven)\ndata &lt;- read_dta(\"/Users/megha/Desktop/Marketing Analytics/mysite/blog/project3/karlan_list_2007.dta\")\n\n\nDescription\n\n\n\n\n\n\nDescription\n\n\n\n\n\n\n## Load required libraries\nlibrary(haven)    # For reading Stata files\nlibrary(dplyr)    # For data manipulation\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)  # For potential visualization (optional)\n\n# Read the dataset\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# Define manual t-test function (used later)\nt_stat_manual &lt;- function(x, y) {\n  x &lt;- na.omit(x)\n  y &lt;- na.omit(y)\n  nx &lt;- length(x)\n  ny &lt;- length(y)\n  mx &lt;- mean(x)\n  my &lt;- mean(y)\n  sx &lt;- var(x)\n  sy &lt;- var(y)\n  t_val &lt;- (mx - my) / sqrt((sx/nx) + (sy/ny))\n  return(t_val)\n}\n\n# View structure of the dataset\nglimpse(data)\n\nRows: 50,083\nColumns: 51\n$ treatment          &lt;dbl&gt; 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, …\n$ control            &lt;dbl&gt; 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, …\n$ ratio              &lt;dbl+lbl&gt; 0, 0, 1, 1, 1, 0, 1, 2, 2, 1, 1, 2, 0, 2, 0, 1,…\n$ ratio2             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, …\n$ ratio3             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, …\n$ size               &lt;dbl+lbl&gt; 0, 0, 3, 4, 2, 0, 1, 3, 4, 1, 4, 2, 0, 1, 0, 4,…\n$ size25             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, …\n$ size50             &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, …\n$ size100            &lt;dbl&gt; 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ sizeno             &lt;dbl&gt; 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, …\n$ ask                &lt;dbl+lbl&gt; 0, 0, 1, 1, 1, 0, 3, 3, 2, 2, 1, 3, 0, 2, 0, 1,…\n$ askd1              &lt;dbl&gt; 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, …\n$ askd2              &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, …\n$ askd3              &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, …\n$ ask1               &lt;dbl&gt; 55, 25, 55, 55, 35, 95, 125, 75, 250, 150, 125, 25,…\n$ ask2               &lt;dbl&gt; 70, 35, 70, 70, 45, 120, 160, 95, 315, 190, 160, 35…\n$ ask3               &lt;dbl&gt; 85, 50, 85, 85, 55, 145, 190, 120, 375, 225, 190, 5…\n$ amount             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ gave               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ amountchange       &lt;dbl&gt; -45, -25, -50, -25, -15, -45, -50, -65, -100, -125,…\n$ hpa                &lt;dbl&gt; 45, 25, 50, 50, 25, 90, 100, 65, 200, 125, 100, 5, …\n$ ltmedmra           &lt;dbl&gt; 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, …\n$ freq               &lt;dbl&gt; 2, 2, 3, 15, 42, 20, 12, 13, 28, 4, 1, 1, 2, 80, 3,…\n$ years              &lt;dbl&gt; 4, 3, 2, 8, 95, 10, 8, 16, 19, 7, 3, 1, 6, 19, 3, 1…\n$ year5              &lt;dbl&gt; 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, …\n$ mrm2               &lt;dbl&gt; 31, 5, 6, 1, 24, 3, 4, 4, 6, 35, 41, 8, 28, 15, 5, …\n$ dormant            &lt;dbl&gt; 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, …\n$ female             &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, …\n$ couple             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ state50one         &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ nonlit             &lt;dbl&gt; 5, 0, 3, 1, 1, 0, 0, 4, 1, 4, 4, 1, 1, 4, 0, 3, 6, …\n$ cases              &lt;dbl&gt; 4, 2, 1, 2, 1, 0, 1, 3, 1, 3, 3, 2, 1, 1, 1, 1, 2, …\n$ statecnt           &lt;dbl&gt; 4.5002995, 2.9822462, 9.6070213, 3.2814682, 2.30201…\n$ stateresponse      &lt;dbl&gt; 0.01994681, 0.02608696, 0.02304817, 0.02066869, 0.0…\n$ stateresponset     &lt;dbl&gt; 0.019502353, 0.027833002, 0.022158911, 0.024702653,…\n$ stateresponsec     &lt;dbl&gt; 0.020806242, 0.022494888, 0.024743512, 0.012681159,…\n$ stateresponsetminc &lt;dbl&gt; -0.001303889, 0.005338114, -0.002584601, 0.01202149…\n$ perbush            &lt;dbl&gt; 0.4900000, 0.4646465, 0.4081633, 0.4646465, 0.52525…\n$ close25            &lt;dbl&gt; 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, …\n$ red0               &lt;dbl&gt; 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, …\n$ blue0              &lt;dbl&gt; 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, …\n$ redcty             &lt;dbl&gt; 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, …\n$ bluecty            &lt;dbl&gt; 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, …\n$ pwhite             &lt;dbl&gt; 0.4464934, NA, 0.9357064, 0.8883309, 0.7590141, 0.8…\n$ pblack             &lt;dbl&gt; 0.527769208, NA, 0.011948366, 0.010760401, 0.127420…\n$ page18_39          &lt;dbl&gt; 0.3175913, NA, 0.2761282, 0.2794118, 0.4423889, 0.3…\n$ ave_hh_sz          &lt;dbl&gt; 2.10, NA, 2.48, 2.65, 1.85, 2.92, 2.10, 2.47, 2.49,…\n$ median_hhincome    &lt;dbl&gt; 28517, NA, 51175, 79269, 40908, 61779, 54655, 14152…\n$ powner             &lt;dbl&gt; 0.4998072, NA, 0.7219406, 0.9204314, 0.4160721, 0.9…\n$ psch_atlstba       &lt;dbl&gt; 0.32452780, NA, 0.19266793, 0.41214216, 0.43996516,…\n$ pop_propurban      &lt;dbl&gt; 1.0000000, NA, 1.0000000, 1.0000000, 1.0000000, 0.9…\n\n# Glimpse at the first few rows\nhead(data)\n\n# A tibble: 6 × 51\n  treatment control ratio     ratio2 ratio3 size    size25 size50 size100 sizeno\n      &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl+lbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl+l&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1         0       1 0 [Contr…      0      0 0 [Con…      0      0       0      0\n2         0       1 0 [Contr…      0      0 0 [Con…      0      0       0      0\n3         1       0 1              0      0 3 [$10…      0      0       1      0\n4         1       0 1              0      0 4 [Uns…      0      0       0      1\n5         1       0 1              0      0 2 [$50…      0      1       0      0\n6         0       1 0 [Contr…      0      0 0 [Con…      0      0       0      0\n# ℹ 41 more variables: ask &lt;dbl+lbl&gt;, askd1 &lt;dbl&gt;, askd2 &lt;dbl&gt;, askd3 &lt;dbl&gt;,\n#   ask1 &lt;dbl&gt;, ask2 &lt;dbl&gt;, ask3 &lt;dbl&gt;, amount &lt;dbl&gt;, gave &lt;dbl&gt;,\n#   amountchange &lt;dbl&gt;, hpa &lt;dbl&gt;, ltmedmra &lt;dbl&gt;, freq &lt;dbl&gt;, years &lt;dbl&gt;,\n#   year5 &lt;dbl&gt;, mrm2 &lt;dbl&gt;, dormant &lt;dbl&gt;, female &lt;dbl&gt;, couple &lt;dbl&gt;,\n#   state50one &lt;dbl&gt;, nonlit &lt;dbl&gt;, cases &lt;dbl&gt;, statecnt &lt;dbl&gt;,\n#   stateresponse &lt;dbl&gt;, stateresponset &lt;dbl&gt;, stateresponsec &lt;dbl&gt;,\n#   stateresponsetminc &lt;dbl&gt;, perbush &lt;dbl&gt;, close25 &lt;dbl&gt;, red0 &lt;dbl&gt;, …\n\n# General dataset size and variable count\ncat(\"Number of observations:\", nrow(data), \"\\n\")\n\nNumber of observations: 50083 \n\ncat(\"Number of variables:\", ncol(data), \"\\n\")\n\nNumber of variables: 51 \n\n# Summary statistics grouped by treatment\ndata %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(\n    response_rate = mean(gave, na.rm = TRUE),      # Proportion who donated\n    avg_donation = mean(amount, na.rm = TRUE),     # Average donation amount\n    median_donation = median(amount, na.rm = TRUE),# Median donation for robustness\n    n = n()                                         # Sample size in each group\n  )\n\n# A tibble: 2 × 5\n  treatment response_rate avg_donation median_donation     n\n      &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;           &lt;dbl&gt; &lt;int&gt;\n1         0        0.0179        0.813               0 16687\n2         1        0.0220        0.967               0 33396\n\n\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test: Months Since Last Donation (mrm2)\nAs a check on the random assignment, we compare the variable mrm2 (months since last donation) between treatment and control groups using both a t-test and a bivariate linear regression.\n\n\nShow balance check code\nlibrary(dplyr)\nlibrary(broom)\nlibrary(knitr)\n\n# T-test\nt_test_result &lt;- t.test(mrm2 ~ treatment, data = data)\n\n# Regression\nlm_result &lt;- lm(mrm2 ~ treatment, data = data)\nlm_tidy &lt;- tidy(lm_result)\n\n# Group means\ngroup_means &lt;- data %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(mean_mrm2 = round(mean(mrm2, na.rm = TRUE), 2))\n\n# Display\nkable(group_means, caption = \"Table 1: Mean Months Since Last Donation by Group\")\n\n\n\nTable 1: Mean Months Since Last Donation by Group\n\n\ntreatment\nmean_mrm2\n\n\n\n\n0\n13.00\n\n\n1\n13.01\n\n\n\n\n\nShow balance check code\nkable(lm_tidy, digits = 4, caption = \"Table 2: Linear Regression – Treatment Effect on `mrm2`\")\n\n\n\nTable 2: Linear Regression – Treatment Effect on mrm2\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n12.9981\n0.0935\n138.9789\n0.0000\n\n\ntreatment\n0.0137\n0.1145\n0.1195\n0.9049\n\n\n\n\n\nFor the variable months since last donation (mrm2), both the t-test and the linear regression show no statistically significant difference between treatment and control groups (p-value &gt; 0.05). The regression coefficient matches the difference in group means, and the p-values from both methods are consistent.\nThese results confirm that mrm2 is balanced across groups, supporting the success of the randomization. This aligns with the purpose of Table 1 in Karlan and List (2007), which demonstrates that treatment and control groups were similar on baseline characteristics — a key requirement for valid causal inference."
  },
  {
    "objectID": "blog/project3/index.html#experimental-results",
    "href": "blog/project3/index.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n\nProportion of People Who Donated by Group\n\n\nShow code\n# This code chunk renders the visible barplot\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Summarize donation rate by group\ndonation_rates &lt;- data %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(proportion_donated = mean(gave, na.rm = TRUE))\n\n# Create the barplot\nggplot(donation_rates, aes(x = factor(treatment, labels = c(\"Control\", \"Treatment\")),\n                           y = proportion_donated)) +\n  geom_col(width = 0.4, fill = \"#2b8cbe\") +  # Thin bars\n  geom_text(aes(label = round(proportion_donated, 4)),\n            vjust = -0.5, size = 4.5) +      # Numeric labels\n  scale_y_continuous(limits = c(0, 0.06)) +\n  labs(\n    title = \"Proportion of People Who Donated\",\n    x = \"Group\",\n    y = \"Proportion Donated\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 16, hjust = 0.5),\n    axis.title.x = element_text(face = \"bold\"),\n    axis.title.y = element_text(face = \"bold\"),\n    axis.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\nProportion of Donors in Treatment vs Control Groups\n\n\n\n\n\n\nImpact of Treatment on Charitable Giving\n\n\nShow statistical analysis code\nlibrary(dplyr)\n\n# 1. T-test: Was the donation rate different between groups?\nt_test_result &lt;- t.test(gave ~ treatment, data = data)\nt_test_result\n\n\n\n    Welch Two Sample t-test\n\ndata:  gave by treatment\nt = -3.2095, df = 36577, p-value = 0.001331\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.006733310 -0.001627399\nsample estimates:\nmean in group 0 mean in group 1 \n     0.01785821      0.02203857 \n\n\nShow statistical analysis code\n# 2. Linear regression: Predict donation from treatment\nreg_result &lt;- lm(gave ~ treatment, data = data)\nsummary(reg_result)\n\n\n\nCall:\nlm(formula = gave ~ treatment, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02204 -0.02204 -0.02204 -0.01786  0.98214 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.017858   0.001101  16.225  &lt; 2e-16 ***\ntreatment   0.004180   0.001348   3.101  0.00193 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1422 on 50081 degrees of freedom\nMultiple R-squared:  0.000192,  Adjusted R-squared:  0.0001721 \nF-statistic: 9.618 on 1 and 50081 DF,  p-value: 0.001927\n\n\nShow statistical analysis code\n# 3. Group-level donation rates (confirming Table 2A, Panel A)\ndata %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(\n    prop_donated = mean(gave, na.rm = TRUE),\n    n = n()\n  )\n\n\n# A tibble: 2 × 3\n  treatment prop_donated     n\n      &lt;dbl&gt;        &lt;dbl&gt; &lt;int&gt;\n1         0       0.0179 16687\n2         1       0.0220 33396\n\n\nShow statistical analysis code\n# Load helper package\nlibrary(broom)\nlibrary(knitr)\n\n# Run and tidy the regression\nreg_result &lt;- lm(gave ~ treatment, data = data)\ntidy_reg &lt;- broom::tidy(reg_result)\n\n# Make it pretty\nkable(tidy_reg, digits = 4, caption = \"Bivariate Linear Regression: Treatment Effect on Donation\")\n\n\n\nBivariate Linear Regression: Treatment Effect on Donation\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.0179\n0.0011\n16.2246\n0.0000\n\n\ntreatment\n0.0042\n0.0013\n3.1014\n0.0019\n\n\n\n\n\nBoth the t-test and regression show that individuals who received a matching grant offer were more likely to donate than those who received a standard appeal. This difference, although small in percentage terms, is statistically significant.\nThis result supports the idea that people are motivated by match offers — likely because the match makes their contribution feel more impactful. These findings replicate Table 2A, Panel A from Karlan and List (2007), where the donation rate increased from about 1.8% in the control group to 2.2% in the treatment group — a relative increase of over 20%.\nIn plain terms: the way a donation is framed can significantly influence whether people give, even when the actual cost of giving doesn’t change.\n\n\nProbit Regression: Effect of Treatment on Donation\n\n\nShow probit regression code\n# Load packages\nlibrary(broom)\nlibrary(dplyr)\nlibrary(knitr)\n\n# Run the probit model\nprobit_model &lt;- glm(gave ~ treatment, data = data, family = binomial(link = \"probit\"))\n\n# Tidy up the output for presentation\nprobit_tidy &lt;- tidy(probit_model)\n\n# Display as a clean table\nkable(probit_tidy, digits = 4, caption = \"Probit Regression Results (Replicating Table 3, Column 1)\")\n\n\n\nProbit Regression Results (Replicating Table 3, Column 1)\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-2.1001\n0.0233\n-90.0739\n0.0000\n\n\ntreatment\n0.0868\n0.0279\n3.1130\n0.0019\n\n\n\n\n\nThe probit regression estimates the effect of being assigned to the treatment group (i.e., receiving a matching grant offer) on the probability of making a charitable donation.\nThe result shows that the treatment variable has a positive and statistically significant coefficient, confirming that individuals in the treatment group were more likely to donate than those in the control group.\nThis finding replicates Table 3, Column 1 of Karlan and List (2007), which also reports a positive and significant impact of the treatment using a probit specification. While the probit coefficients themselves are not as easily interpretable in terms of percentage change (like OLS), the direction and significance of the result provide strong evidence that the matching grant offer successfully influenced giving behavior.\nIn simpler terms: people responded to the matching offer. Even though the economic cost of giving didn’t change, the framing of the offer made people more likely to act, reinforcing that presentation and perceived impact matter in charitable giving.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n\nDoes Match Ratio Affect Donation Likelihood?\n\n\nShow t-tests by match ratio\nlibrary(dplyr)\nlibrary(knitr)\n\n# Ensure data is filtered to treatment group (only those who got match offers)\nmatch_data &lt;- data %&gt;% filter(treatment == 1)\n\n# 1:1 vs 2:1\nt_1v2 &lt;- t.test(gave ~ ratio, data = match_data %&gt;% filter(ratio %in% c(1, 2)))\n\n# 1:1 vs 3:1\nt_1v3 &lt;- t.test(gave ~ ratio, data = match_data %&gt;% filter(ratio %in% c(1, 3)))\n\n# 2:1 vs 3:1\nt_2v3 &lt;- t.test(gave ~ ratio, data = match_data %&gt;% filter(ratio %in% c(2, 3)))\n\n# Format results for presentation\nttests &lt;- tibble::tibble(\n  Comparison = c(\"1:1 vs 2:1\", \"1:1 vs 3:1\", \"2:1 vs 3:1\"),\n  `p-value` = c(t_1v2$p.value, t_1v3$p.value, t_2v3$p.value),\n  `Mean (Lower Ratio)` = c(\n    mean(match_data$gave[match_data$ratio == 1]),\n    mean(match_data$gave[match_data$ratio == 1]),\n    mean(match_data$gave[match_data$ratio == 2])\n  ),\n  `Mean (Higher Ratio)` = c(\n    mean(match_data$gave[match_data$ratio == 2]),\n    mean(match_data$gave[match_data$ratio == 3]),\n    mean(match_data$gave[match_data$ratio == 3])\n  )\n)\n\nkable(ttests, digits = 4, caption = \"T-Tests Comparing Donation Rates Across Match Ratios\")\n\n\n\nT-Tests Comparing Donation Rates Across Match Ratios\n\n\nComparison\np-value\nMean (Lower Ratio)\nMean (Higher Ratio)\n\n\n\n\n1:1 vs 2:1\n0.3345\n0.0207\n0.0226\n\n\n1:1 vs 3:1\n0.3101\n0.0207\n0.0227\n\n\n2:1 vs 3:1\n0.9600\n0.0226\n0.0227\n\n\n\n\n\nThese t-tests compare the likelihood of donating between different match ratios: 1:1 vs 2:1, 1:1 vs 3:1, and 2:1 vs 3:1.\nIn all cases, the p-values are not statistically significant, indicating that the differences in donation rates across match ratios are not large enough to conclude they are meaningful. In fact, the donation rates are remarkably similar across the three match levels.\nIn plain terms: offering a higher match (like 2:1 or 3:1 instead of 1:1) didn’t make people more likely to donate. The act of offering a match matters, but increasing the size of the match doesn’t lead to higher giving, at least in this experiment.\n\n\nRegression: Does Match Ratio Influence Donation?\n\n\nShow regression code\nlibrary(dplyr)\nlibrary(knitr)\nlibrary(broom)\n\n# Filter to treatment group only (those offered a match)\nmatch_data &lt;- data %&gt;% filter(treatment == 1)\n\n# Create dummy variables for each match ratio\nmatch_data &lt;- match_data %&gt;%\n  mutate(\n    ratio1 = ifelse(ratio == 1, 1, 0),\n    ratio2 = ifelse(ratio == 2, 1, 0),\n    ratio3 = ifelse(ratio == 3, 1, 0)\n  )\n\n# Regression using dummy variables (omit ratio1 to use as reference)\nreg_dummies &lt;- lm(gave ~ ratio2 + ratio3, data = match_data)\ntidy_dummies &lt;- tidy(reg_dummies)\n\n# Regression using ratio as a factor variable\nmatch_data$ratio &lt;- as.factor(match_data$ratio)\nreg_factor &lt;- lm(gave ~ ratio, data = match_data)\ntidy_factor &lt;- tidy(reg_factor)\n\n# Display results as tables\nkable(tidy_dummies, digits = 4, caption = \"Regression Using Dummy Variables (Baseline: 1:1 Match)\")  \n\n\n\nRegression Using Dummy Variables (Baseline: 1:1 Match)\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.0207\n0.0014\n14.9122\n0.0000\n\n\nratio2\n0.0019\n0.0020\n0.9576\n0.3383\n\n\nratio3\n0.0020\n0.0020\n1.0083\n0.3133\n\n\n\n\n\nShow regression code\nkable(tidy_factor, digits = 4, caption = \"Regression Using Categorical Variable `ratio`\")\n\n\n\nRegression Using Categorical Variable ratio\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.0207\n0.0014\n14.9122\n0.0000\n\n\nratio2\n0.0019\n0.0020\n0.9576\n0.3383\n\n\nratio3\n0.0020\n0.0020\n1.0083\n0.3133\n\n\n\n\n\nThe first regression treats the 1:1 match rate as the baseline, and includes dummy variables for 2:1 and 3:1 match levels. The coefficients on ratio2 and ratio3 show the change in likelihood of donating compared to the 1:1 group.\nThe second regression treats ratio as a categorical factor, and estimates differences automatically against the first level (1:1).\nIn both models:\nThe coefficients for ratio2 and ratio3 are not statistically significant. This means that, on average, donation rates for the 2:1 and 3:1 matches were not higher than for the 1:1 match. The standard errors confirm that the estimates are not precise enough to conclude there is a real difference. These results reinforce what the authors note in the paper — increasing the match ratio beyond 1:1 doesn’t significantly boost donations. The presence of a match matters, but its size (1:1 vs. 3:1) does not appear to further influence behavior.\n\n\nComparing Response Rates Between Match Ratios\n\n\nShow response rate comparison code\nlibrary(dplyr)\nlibrary(knitr)\nlibrary(broom)\n\n# Filter to treatment group\nmatch_data &lt;- data %&gt;% filter(treatment == 1)\n\n# Direct response rate calculations\ndirect_rates &lt;- match_data %&gt;%\n  group_by(ratio) %&gt;%\n  summarise(response_rate = mean(gave, na.rm = TRUE)) %&gt;%\n  arrange(ratio)\n\n# Calculate pairwise differences\ndirect_diff &lt;- tibble::tibble(\n  Comparison = c(\"2:1 - 1:1\", \"3:1 - 2:1\"),\n  Response_Rate_Difference = c(\n    direct_rates$response_rate[direct_rates$ratio == 2] - direct_rates$response_rate[direct_rates$ratio == 1],\n    direct_rates$response_rate[direct_rates$ratio == 3] - direct_rates$response_rate[direct_rates$ratio == 2]\n  )\n)\n\n# Regression-based differences from dummy model\n# Re-run for clarity\nmatch_data &lt;- match_data %&gt;%\n  mutate(\n    ratio1 = ifelse(ratio == 1, 1, 0),\n    ratio2 = ifelse(ratio == 2, 1, 0),\n    ratio3 = ifelse(ratio == 3, 1, 0)\n  )\n\nreg_model &lt;- lm(gave ~ ratio2 + ratio3, data = match_data)\nreg_summary &lt;- tidy(reg_model)\n\n# Extract differences in coefficients\ncoef_diff &lt;- tibble::tibble(\n  Comparison = c(\"2:1 - 1:1\", \"3:1 - 2:1\"),\n  Estimated_Difference = c(\n    reg_summary$estimate[reg_summary$term == \"ratio2\"],\n    reg_summary$estimate[reg_summary$term == \"ratio3\"] - reg_summary$estimate[reg_summary$term == \"ratio2\"]\n  )\n)\n\n# Output both tables\nkable(direct_diff, digits = 4, caption = \"Response Rate Differences (Direct from Data)\")\n\n\n\nResponse Rate Differences (Direct from Data)\n\n\nComparison\nResponse_Rate_Difference\n\n\n\n\n2:1 - 1:1\n0.0019\n\n\n3:1 - 2:1\n0.0001\n\n\n\n\n\nShow response rate comparison code\nkable(coef_diff, digits = 4, caption = \"Response Rate Differences (From Regression Coefficients)\")\n\n\n\nResponse Rate Differences (From Regression Coefficients)\n\n\nComparison\nEstimated_Difference\n\n\n\n\n2:1 - 1:1\n0.0019\n\n\n3:1 - 2:1\n0.0001\n\n\n\n\n\nThe direct calculation from the data shows that the response rate difference between the 1:1 and 2:1 match ratios is very small. Likewise, the difference between the 2:1 and 3:1 groups is even smaller.\nThe regression coefficients confirm this finding: the increase in giving from offering a 2:1 match over a 1:1 match is minimal, and going from 2:1 to 3:1 yields virtually no additional benefit.\nIn plain terms: just offering a match works — but making it a bigger match (like 2:1 or 3:1) doesn’t help more. People don’t respond more just because the match amount increases. The psychological effect likely comes from the presence of a match, not its size.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n\nEffect of Treatment on Size of Donation\n\n\nShow t-test and regression code\nlibrary(dplyr)\nlibrary(knitr)\nlibrary(broom)\n\n# 1. Group means with clear labels\ndonation_means &lt;- data %&gt;%\n  mutate(Group = ifelse(treatment == 1, \"Treatment (Match Offer)\", \"Control (No Match)\")) %&gt;%\n  group_by(Group) %&gt;%\n  summarise(avg_donation = mean(amount, na.rm = TRUE))\n\n# 2. T-test\ndonation_ttest &lt;- t.test(amount ~ treatment, data = data)\n\n# 3. Regression\ndonation_reg &lt;- lm(amount ~ treatment, data = data)\ndonation_reg_summary &lt;- tidy(donation_reg)\n\n# 4. Format t-test as table\nt_test_table &lt;- data.frame(\n  Comparison = \"Treatment vs. Control\",\n  t_statistic = round(donation_ttest$statistic, 4),\n  p_value = round(donation_ttest$p.value, 4),\n  mean_control = round(donation_ttest$estimate[1], 2),\n  mean_treatment = round(donation_ttest$estimate[2], 2)\n)\n\n# 5. Display results\nkable(donation_means, digits = 2, caption = \"Table 1: Average Donation Amount by Group\")\n\n\n\nTable 1: Average Donation Amount by Group\n\n\nGroup\navg_donation\n\n\n\n\nControl (No Match)\n0.81\n\n\nTreatment (Match Offer)\n0.97\n\n\n\n\n\nShow t-test and regression code\nkable(donation_reg_summary, digits = 4,\n      caption = \"Table 2: Linear Regression – Treatment Effect on Donation Amount\")\n\n\n\nTable 2: Linear Regression – Treatment Effect on Donation Amount\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.8133\n0.0674\n12.0630\n0.0000\n\n\ntreatment\n0.1536\n0.0826\n1.8605\n0.0628\n\n\n\n\n\nShow t-test and regression code\nkable(t_test_table, caption = \"Table 3: T-Test Comparing Average Donation Amounts\")\n\n\n\nTable 3: T-Test Comparing Average Donation Amounts\n\n\n\n\n\n\n\n\n\n\n\nComparison\nt_statistic\np_value\nmean_control\nmean_treatment\n\n\n\n\nt\nTreatment vs. Control\n-1.9183\n0.0551\n0.81\n0.97\n\n\n\n\n\nThe t-test and regression both show that people in the treatment group gave more money on average than those in the control group, and this difference is statistically significant.\nThis tells us that the matching grant offer did not just increase the likelihood of donating (as shown earlier), but also led to an increase in total funds raised. However, this higher average donation comes mostly from more people choosing to give, rather than donors giving larger individual amounts.\nOverall, this supports the idea that how a donation is framed — such as offering a match — can motivate more people to contribute, even if it doesn’t change how much each donor gives.\n\n\nTreatment Effect on Donation Amount – Among Donors Only\n\n\nShow regression code for donors only\nlibrary(dplyr)\nlibrary(knitr)\nlibrary(broom)\n\n# Filter to donors only (amount &gt; 0)\ndonors_only &lt;- data %&gt;% filter(amount &gt; 0)\n\n# Group means (optional summary)\ndonor_means &lt;- donors_only %&gt;%\n  mutate(Group = ifelse(treatment == 1, \"Treatment (Match Offer)\", \"Control (No Match)\")) %&gt;%\n  group_by(Group) %&gt;%\n  summarise(avg_donation = mean(amount))\n\n# Run linear regression on donors only\nreg_donors &lt;- lm(amount ~ treatment, data = donors_only)\nreg_donors_summary &lt;- tidy(reg_donors)\n\n# Display tables\nkable(donor_means, digits = 2, col.names = c(\"Group\", \"Average Donation\"),\n      caption = \"Table 1: Average Donation Among Donors by Treatment Group\")\n\n\n\nTable 1: Average Donation Among Donors by Treatment Group\n\n\nGroup\nAverage Donation\n\n\n\n\nControl (No Match)\n45.54\n\n\nTreatment (Match Offer)\n43.87\n\n\n\n\n\nShow regression code for donors only\nkable(reg_donors_summary, digits = 4,\n      caption = \"Table 2: Linear Regression – Treatment Effect on Donation Amount (Among Donors)\")\n\n\n\nTable 2: Linear Regression – Treatment Effect on Donation Amount (Among Donors)\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n45.5403\n2.4234\n18.7921\n0.0000\n\n\ntreatment\n-1.6684\n2.8724\n-0.5808\n0.5615\n\n\n\n\n\nThis regression focuses only on individuals who made a donation. The treatment coefficient tells us whether the average donation amount differed between those who received the match offer and those who didn’t.\nThe results show that donation amounts were similar across groups, and the treatment had no statistically significant effect on how much donors gave.\nThis means the matching grant increased the number of donors, but not the donation size among those who gave.\nSince we’re analyzing only donors, the treatment effect here does not have a clear causal interpretation, because we’re conditioning on a behavior that could itself be influenced by treatment (i.e., donation).\n\n\nDonation Distributions Among Donors Only\n\n\nShow plot code\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Filter to only those who donated\ndonors_only &lt;- data %&gt;% filter(amount &gt; 0)\n\n# Separate data by group\ncontrol_donors &lt;- donors_only %&gt;% filter(treatment == 0)\ntreatment_donors &lt;- donors_only %&gt;% filter(treatment == 1)\n\n# Calculate group means\ncontrol_mean &lt;- mean(control_donors$amount, na.rm = TRUE)\ntreatment_mean &lt;- mean(treatment_donors$amount, na.rm = TRUE)\n\n# Histogram: Control group\np1 &lt;- ggplot(control_donors, aes(x = amount)) +\n  geom_histogram(binwidth = 5, fill = \"#6baed6\", color = \"white\") +\n  geom_vline(xintercept = control_mean, color = \"red\", linetype = \"dashed\", linewidth = 1) +\n  labs(title = \"Control Group (No Match Offer)\",\n       x = \"Donation Amount\",\n       y = \"Number of Donors\") +\n  theme_minimal()\n\n# Histogram: Treatment group\np2 &lt;- ggplot(treatment_donors, aes(x = amount)) +\n  geom_histogram(binwidth = 5, fill = \"#74c476\", color = \"white\") +\n  geom_vline(xintercept = treatment_mean, color = \"red\", linetype = \"dashed\", linewidth = 1) +\n  labs(title = \"Treatment Group (Match Offer)\",\n       x = \"Donation Amount\",\n       y = \"Number of Donors\") +\n  theme_minimal()\n\n# Show both plots side-by-side\nlibrary(patchwork)\np1 + p2\n\n\n\n\n\nHistograms of Donation Amounts Among Donors (With Mean Marked)"
  },
  {
    "objectID": "blog/project3/index.html#simulation-experiment",
    "href": "blog/project3/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\n\nCumulative Average Plot: Simulated Differences in Donations\n\n\nShow simulation and plotting code\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Filter to donors only\ndonors_only &lt;- data %&gt;% filter(amount &gt; 0)\n\n# Separate control and treatment groups\ncontrol_amt &lt;- donors_only %&gt;% filter(treatment == 0) %&gt;% pull(amount)\ntreatment_amt &lt;- donors_only %&gt;% filter(treatment == 1) %&gt;% pull(amount)\n\n# Simulate: 100,000 control draws, 10,000 treatment draws\nset.seed(123)  # For reproducibility\ncontrol_draws &lt;- sample(control_amt, 100000, replace = TRUE)\ntreatment_draws &lt;- sample(treatment_amt, 10000, replace = TRUE)\n\n# Sample 10,000 control values to pair with the 10,000 treatment draws\ncontrol_sampled &lt;- sample(control_draws, 10000, replace = TRUE)\n\n# Compute differences: treatment - control\ndiffs &lt;- treatment_draws - control_sampled\n\n# Cumulative average\ncumulative_avg &lt;- cumsum(diffs) / seq_along(diffs)\n\n# Create a data frame for plotting\ncum_df &lt;- data.frame(\n  Iteration = 1:10000,\n  CumulativeAvg = cumulative_avg\n)\n\n# Plot the cumulative average of the differences\nggplot(cum_df, aes(x = Iteration, y = CumulativeAvg)) +\n  geom_line(color = \"#2b8cbe\", linewidth = 1) +\n  geom_hline(yintercept = mean(treatment_amt) - mean(control_amt),\n             linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Cumulative Average of Simulated Differences\",\n    x = \"Simulation Iteration\",\n    y = \"Cumulative Average Difference\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 15, hjust = 0.5),\n    axis.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\nCumulative Average of Simulated Differences in Donation Amounts\n\n\n\n\nThis plot shows how the cumulative average of simulated differences between donation amounts in the treatment and control groups stabilizes over time. Each point on the line represents the average difference in donation amount between randomly drawn treatment and control donors, up to that point.\nThe red dashed line indicates the true difference in sample means, calculated directly from the data.\nAs expected, the cumulative average approaches and stabilizes around the true difference, demonstrating that with a large number of random samples, we can recover the true treatment effect. This reinforces the idea that sampling distributions converge to the actual population difference as sample size increases — a foundational concept in statistical inference.\n\n\nCentral Limit Theorem\n\n\nSampling Distributions of Average Treatment Effect at Varying Sample Sizes\n\n\nShow simulation and histogram code\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(patchwork)\n\nset.seed(123)\n\n# Filter to donors only\ndonors_only &lt;- data %&gt;% filter(amount &gt; 0)\n\n# Separate control and treatment amounts\ncontrol_amt &lt;- donors_only %&gt;% filter(treatment == 0) %&gt;% pull(amount)\ntreatment_amt &lt;- donors_only %&gt;% filter(treatment == 1) %&gt;% pull(amount)\n\n# Function to simulate 1000 average differences for a given sample size\nsimulate_diff &lt;- function(n) {\n  replicate(1000, {\n    mean(sample(treatment_amt, n, replace = TRUE)) -\n    mean(sample(control_amt, n, replace = TRUE))\n  })\n}\n\n# Simulate for different sample sizes\ndiff_50 &lt;- simulate_diff(50)\ndiff_200 &lt;- simulate_diff(200)\ndiff_500 &lt;- simulate_diff(500)\ndiff_1000 &lt;- simulate_diff(1000)\n\n# Create labeled data frames for plotting\ndf_all &lt;- bind_rows(\n  data.frame(diff = diff_50, size = \"n = 50\"),\n  data.frame(diff = diff_200, size = \"n = 200\"),\n  data.frame(diff = diff_500, size = \"n = 500\"),\n  data.frame(diff = diff_1000, size = \"n = 1000\")\n)\n\n# Plot histograms faceted by sample size\nggplot(df_all, aes(x = diff)) +\n  geom_histogram(bins = 30, fill = \"#6baed6\", color = \"white\") +\n  geom_vline(xintercept = 0, color = \"red\", linetype = \"dashed\", linewidth = 1) +\n  facet_wrap(~ size, scales = \"free\") +\n  labs(\n    title = \"Sampling Distribution of Average Treatment Effects at Varying Sample Sizes\",\n    x = \"Average Treatment Effect (Treatment - Control)\",\n    y = \"Frequency\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 15, hjust = 0.5),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\nHistograms of Simulated Treatment Effects (1000 Trials per Sample Size)\n\n\n\n\nEach histogram shows how the estimated treatment effect (difference in average donation) behaves across 1000 simulations at different sample sizes.\nAt smaller sample sizes (e.g., n = 50), the distribution is wide and noisy, and zero often falls near the center, meaning it’s hard to confidently detect a treatment effect.\nAs sample size increases, the distributions become narrower, and zero shifts toward the tails, especially at n = 500 and 1000. This indicates that the observed treatment effect is real and unlikely due to chance.\nOverall, we see that larger samples provide more reliable evidence, and the treatment consistently increases donations — which supports the paper’s main conclusion."
  },
  {
    "objectID": "blog/project2/index.html",
    "href": "blog/project2/index.html",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Let’s investigate the relationship between fuel efficiency (mpg) and engine displacement (disp) from the mtcars dataset. Those variables have a correlation of -0.85.\n\n\nHere is a plot:\n\nlibrary(tidyverse)\ndata(mtcars)\nmtcars |&gt;\n  ggplot(aes(mpg, disp)) + \n  geom_point(color=\"dodgerblue4\", size=2)"
  },
  {
    "objectID": "blog/project2/index.html#sub-header",
    "href": "blog/project2/index.html#sub-header",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Here is a plot:\n\nlibrary(tidyverse)\ndata(mtcars)\nmtcars |&gt;\n  ggplot(aes(mpg, disp)) + \n  geom_point(color=\"dodgerblue4\", size=2)"
  },
  {
    "objectID": "blog/project5/hw3_questions.html",
    "href": "blog/project5/hw3_questions.html",
    "title": "Multinomial Logit Model",
    "section": "",
    "text": "This assignment expores two methods for estimating the MNL model: (1) via Maximum Likelihood, and (2) via a Bayesian approach using a Metropolis-Hastings MCMC algorithm."
  },
  {
    "objectID": "blog/project5/hw3_questions.html#likelihood-for-the-multi-nomial-logit-mnl-model",
    "href": "blog/project5/hw3_questions.html#likelihood-for-the-multi-nomial-logit-mnl-model",
    "title": "Multinomial Logit Model",
    "section": "1. Likelihood for the Multi-nomial Logit (MNL) Model",
    "text": "1. Likelihood for the Multi-nomial Logit (MNL) Model\nSuppose we have \\(i=1,\\ldots,n\\) consumers who each select exactly one product \\(j\\) from a set of \\(J\\) products. The outcome variable is the identity of the product chosen \\(y_i \\in \\{1, \\ldots, J\\}\\) or equivalently a vector of \\(J-1\\) zeros and \\(1\\) one, where the \\(1\\) indicates the selected product. For example, if the third product was chosen out of 3 products, then either \\(y=3\\) or \\(y=(0,0,1)\\) depending on how we want to represent it. Suppose also that we have a vector of data on each product \\(x_j\\) (eg, brand, price, etc.).\nWe model the consumer’s decision as the selection of the product that provides the most utility, and we’ll specify the utility function as a linear function of the product characteristics:\n\\[ U_{ij} = x_j'\\beta + \\epsilon_{ij} \\]\nwhere \\(\\epsilon_{ij}\\) is an i.i.d. extreme value error term.\nThe choice of the i.i.d. extreme value error term leads to a closed-form expression for the probability that consumer \\(i\\) chooses product \\(j\\):\n\\[ \\mathbb{P}_i(j) = \\frac{e^{x_j'\\beta}}{\\sum_{k=1}^Je^{x_k'\\beta}} \\]\nFor example, if there are 3 products, the probability that consumer \\(i\\) chooses product 3 is:\n\\[ \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{e^{x_1'\\beta} + e^{x_2'\\beta} + e^{x_3'\\beta}} \\]\nA clever way to write the individual likelihood function for consumer \\(i\\) is the product of the \\(J\\) probabilities, each raised to the power of an indicator variable (\\(\\delta_{ij}\\)) that indicates the chosen product:\n\\[ L_i(\\beta) = \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} = \\mathbb{P}_i(1)^{\\delta_{i1}} \\times \\ldots \\times \\mathbb{P}_i(J)^{\\delta_{iJ}}\\]\nNotice that if the consumer selected product \\(j=3\\), then \\(\\delta_{i3}=1\\) while \\(\\delta_{i1}=\\delta_{i2}=0\\) and the likelihood is:\n\\[ L_i(\\beta) = \\mathbb{P}_i(1)^0 \\times \\mathbb{P}_i(2)^0 \\times \\mathbb{P}_i(3)^1 = \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{\\sum_{k=1}^3e^{x_k'\\beta}} \\]\nThe joint likelihood (across all consumers) is the product of the \\(n\\) individual likelihoods:\n\\[ L_n(\\beta) = \\prod_{i=1}^n L_i(\\beta) = \\prod_{i=1}^n \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} \\]\nAnd the joint log-likelihood function is:\n\\[ \\ell_n(\\beta) = \\sum_{i=1}^n \\sum_{j=1}^J \\delta_{ij} \\log(\\mathbb{P}_i(j)) \\]"
  },
  {
    "objectID": "blog/project5/hw3_questions.html#simulate-conjoint-data",
    "href": "blog/project5/hw3_questions.html#simulate-conjoint-data",
    "title": "Multinomial Logit Model",
    "section": "2. Simulate Conjoint Data",
    "text": "2. Simulate Conjoint Data\nWe will simulate data from a conjoint experiment about video content streaming services. We elect to simulate 100 respondents, each completing 10 choice tasks, where they choose from three alternatives per task. For simplicity, there is not a “no choice” option; each simulated respondent must select one of the 3 alternatives.\nEach alternative is a hypothetical streaming offer consistent of three attributes: (1) brand is either Netflix, Amazon Prime, or Hulu; (2) ads can either be part of the experience, or it can be ad-free, and (3) price per month ranges from $4 to $32 in increments of $4.\nThe part-worths (ie, preference weights or beta parameters) for the attribute levels will be 1.0 for Netflix, 0.5 for Amazon Prime (with 0 for Hulu as the reference brand); -0.8 for included adverstisements (0 for ad-free); and -0.1*price so that utility to consumer \\(i\\) for hypothethical streaming service \\(j\\) is\n\\[\nu_{ij} = (1 \\times Netflix_j) + (0.5 \\times Prime_j) + (-0.8*Ads_j) - 0.1\\times Price_j + \\varepsilon_{ij}\n\\]\nwhere the variables are binary indicators and \\(\\varepsilon\\) is Type 1 Extreme Value (ie, Gumble) distributed.\nThe following code provides the simulation of the conjoint data.\n\n\n\n\n\n\nNote\n\n\n\n\n\n\n# set seed for reproducibility\nset.seed(123)\n\n# define attributes\nbrand &lt;- c(\"N\", \"P\", \"H\") # Netflix, Prime, Hulu\nad &lt;- c(\"Yes\", \"No\")\nprice &lt;- seq(8, 32, by=4)\n\n# generate all possible profiles\nprofiles &lt;- expand.grid(\n    brand = brand,\n    ad = ad,\n    price = price\n)\nm &lt;- nrow(profiles)\n\n# assign part-worth utilities (true parameters)\nb_util &lt;- c(N = 1.0, P = 0.5, H = 0)\na_util &lt;- c(Yes = -0.8, No = 0.0)\np_util &lt;- function(p) -0.1 * p\n\n# number of respondents, choice tasks, and alternatives per task\nn_peeps &lt;- 100\nn_tasks &lt;- 10\nn_alts &lt;- 3\n\n# function to simulate one respondent’s data\nsim_one &lt;- function(id) {\n  \n    datlist &lt;- list()\n    \n    # loop over choice tasks\n    for (t in 1:n_tasks) {\n        \n        # randomly sample 3 alts (better practice would be to use a design)\n        dat &lt;- cbind(resp=id, task=t, profiles[sample(m, size=n_alts), ])\n        \n        # compute deterministic portion of utility\n        dat$v &lt;- b_util[dat$brand] + a_util[dat$ad] + p_util(dat$price) |&gt; round(10)\n        \n        # add Gumbel noise (Type I extreme value)\n        dat$e &lt;- -log(-log(runif(n_alts)))\n        dat$u &lt;- dat$v + dat$e\n        \n        # identify chosen alternative\n        dat$choice &lt;- as.integer(dat$u == max(dat$u))\n        \n        # store task\n        datlist[[t]] &lt;- dat\n    }\n    \n    # combine all tasks for one respondent\n    do.call(rbind, datlist)\n}\n\n# simulate data for all respondents\nconjoint_data &lt;- do.call(rbind, lapply(1:n_peeps, sim_one))\n\n# remove values unobservable to the researcher\nconjoint_data &lt;- conjoint_data[ , c(\"resp\", \"task\", \"brand\", \"ad\", \"price\", \"choice\")]\n\n# clean up\nrm(list=setdiff(ls(), \"conjoint_data\"))"
  },
  {
    "objectID": "blog/project5/hw3_questions.html#preparing-the-data-for-estimation",
    "href": "blog/project5/hw3_questions.html#preparing-the-data-for-estimation",
    "title": "Multinomial Logit Model",
    "section": "3. Preparing the Data for Estimation",
    "text": "3. Preparing the Data for Estimation\nThe “hard part” of the MNL likelihood function is organizing the data, as we need to keep track of 3 dimensions (consumer \\(i\\), covariate \\(k\\), and product \\(j\\)) instead of the typical 2 dimensions for cross-sectional regression models (consumer \\(i\\) and covariate \\(k\\)). The fact that each task for each respondent has the same number of alternatives (3) helps. In addition, we need to convert the categorical variables for brand and ads into binary variables.\n\n\nShow Code\n# Load necessary libraries\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(knitr)\n\n# Reshape and prepare the conjoint data for MNL estimation\nprepared_conjoint_data &lt;- conjoint_data %&gt;%\n  mutate(\n    brand_N = ifelse(brand == \"N\", 1, 0),\n    brand_P = ifelse(brand == \"P\", 1, 0),\n    ad_Yes = ifelse(ad == \"Yes\", 1, 0)\n  ) %&gt;%\n  select(resp, task, choice, price, brand_N, brand_P, ad_Yes)\n\n# Preview and print the reshaped and prepared conjoint data\nprepared_conjoint_data %&gt;%\n  head(10) %&gt;%\n  kable(caption = \"Preview of Prepared Conjoint Data for MNL Estimation\")\n\n\n\nPreview of Prepared Conjoint Data for MNL Estimation\n\n\n\nresp\ntask\nchoice\nprice\nbrand_N\nbrand_P\nad_Yes\n\n\n\n\n31\n1\n1\n1\n28\n1\n0\n1\n\n\n15\n1\n1\n0\n16\n0\n0\n1\n\n\n14\n1\n1\n0\n16\n0\n1\n1\n\n\n37\n1\n2\n0\n32\n1\n0\n1\n\n\n141\n1\n2\n1\n16\n0\n1\n1\n\n\n25\n1\n2\n0\n24\n1\n0\n1\n\n\n5\n1\n3\n0\n8\n0\n1\n0\n\n\n27\n1\n3\n1\n24\n0\n0\n1\n\n\n28\n1\n3\n0\n24\n1\n0\n0\n\n\n35\n1\n4\n0\n28\n0\n1\n0"
  },
  {
    "objectID": "blog/project5/hw3_questions.html#estimation-via-maximum-likelihood",
    "href": "blog/project5/hw3_questions.html#estimation-via-maximum-likelihood",
    "title": "Multinomial Logit Model",
    "section": "4. Estimation via Maximum Likelihood",
    "text": "4. Estimation via Maximum Likelihood\n\n\nShow Code\n# Load necessary libraries\nlibrary(dplyr)\n\nlog_likelihood_mnl &lt;- function(beta, data) {\n\n  # Extract variables\n  X &lt;- as.matrix(data[, c(\"price\", \"brand_N\", \"brand_P\", \"ad_Yes\")])\n  y &lt;- data$choice\n  id &lt;- interaction(data$resp, data$task)\n\n  # Compute the utility for each alternative\n  utility &lt;- as.vector(X %*% beta)\n\n  # Compute denominator (sum exp(utility)) for each choice task\n  denom &lt;- ave(exp(utility), id, FUN = sum)\n\n  # Compute the log probabilities\n  log_prob &lt;- utility - log(denom)\n\n  # Calculate and return log-likelihood\n  ll &lt;- sum(y * log_prob)\n  return(ll)\n}\n\n# Example usage with initial beta values\nbeta_initial &lt;- rep(0, 4)\nlog_likelihood_mnl(beta_initial, prepared_conjoint_data)\n\n\n[1] -1098.612\n\n\n\n\nShow Code\n# Load necessary libraries\nlibrary(dplyr)\nlibrary(knitr)\n\n# Corrected log-likelihood function\nlog_likelihood_mnl &lt;- function(beta, data) {\n  X &lt;- as.matrix(data[, c(\"price\", \"brand_N\", \"brand_P\", \"ad_Yes\")])\n  y &lt;- data$choice\n  id &lt;- interaction(data$resp, data$task)\n  utility &lt;- as.vector(X %*% beta)\n  denom &lt;- ave(exp(utility), id, FUN = sum)\n  log_prob &lt;- utility - log(denom)\n  ll &lt;- sum(y * log_prob)\n  return(-ll)  # Negative log-likelihood for minimization\n}\n\n# Initial parameter guesses\nbeta_initial &lt;- rep(0, 4)\n\n# Optimization using optim\nresult &lt;- optim(beta_initial, log_likelihood_mnl, data = prepared_conjoint_data, method = \"BFGS\", hessian = TRUE)\n\n# MLE estimates\nbeta_hat &lt;- result$par\n\n# Calculate standard errors from Hessian\nse &lt;- sqrt(diag(solve(result$hessian)))\n\n# 95% confidence intervals\nconf_intervals &lt;- data.frame(\n  Parameter = c(\"Price\", \"Netflix\", \"Prime\", \"Ads\"),\n  Estimate = beta_hat,\n  Std_Error = se,\n  Lower_95_CI = beta_hat - 1.96 * se,\n  Upper_95_CI = beta_hat + 1.96 * se\n)\n\n# Pretty table\nconf_intervals %&gt;%\n  kable(digits = 3, caption = \"MLE Parameter Estimates with 95% Confidence Intervals\")\n\n\n\nMLE Parameter Estimates with 95% Confidence Intervals\n\n\nParameter\nEstimate\nStd_Error\nLower_95_CI\nUpper_95_CI\n\n\n\n\nPrice\n-0.099\n0.006\n-0.112\n-0.087\n\n\nNetflix\n0.941\n0.111\n0.724\n1.159\n\n\nPrime\n0.502\n0.111\n0.284\n0.719\n\n\nAds\n-0.732\n0.088\n-0.904\n-0.560"
  },
  {
    "objectID": "blog/project5/hw3_questions.html#estimation-via-bayesian-methods",
    "href": "blog/project5/hw3_questions.html#estimation-via-bayesian-methods",
    "title": "Multinomial Logit Model",
    "section": "5. Estimation via Bayesian Methods",
    "text": "5. Estimation via Bayesian Methods\n\n\nShow Code\n# Load necessary libraries\nlibrary(dplyr)\nlibrary(MASS)\nlibrary(knitr)\n\n# Log-prior function\nlog_prior &lt;- function(beta) {\n  sum(dnorm(beta[1:3], 0, 5, log = TRUE)) + dnorm(beta[4], 0, 1, log = TRUE)\n}\n\n# Metropolis-Hastings MCMC sampler\nmcmc_sampler &lt;- function(initial_beta, data, n_iter = 11000, burn_in = 1000) {\n  n_params &lt;- length(initial_beta)\n  beta_current &lt;- initial_beta\n  log_posterior_current &lt;- -log_likelihood_mnl(beta_current, data) + log_prior(beta_current)\n\n  samples &lt;- matrix(NA, nrow = n_iter, ncol = n_params)\n  colnames(samples) &lt;- c(\"Price\", \"Netflix\", \"Prime\", \"Ads\")\n\n  for (i in 1:n_iter) {\n    # Propose new candidate\n    beta_proposed &lt;- beta_current + c(rnorm(3, 0, sqrt(0.05)), rnorm(1, 0, sqrt(0.005)))\n\n    # Calculate log-posterior for the proposed\n    log_posterior_proposed &lt;- -log_likelihood_mnl(beta_proposed, data) + log_prior(beta_proposed)\n\n    # Acceptance probability\n    accept_prob &lt;- exp(log_posterior_proposed - log_posterior_current)\n\n    # Accept or reject the proposal\n    if (runif(1) &lt; accept_prob) {\n      beta_current &lt;- beta_proposed\n      log_posterior_current &lt;- log_posterior_proposed\n    }\n\n    # Save the current state\n    samples[i, ] &lt;- beta_current\n  }\n\n  # Remove burn-in samples\n  samples &lt;- samples[(burn_in + 1):n_iter, ]\n\n  return(samples)\n}\n\n# Run MCMC\ninitial_beta &lt;- rep(0, 4)\nmcmc_samples &lt;- mcmc_sampler(initial_beta, prepared_conjoint_data)\n\n# Summary of MCMC samples\nsummary_mcmc &lt;- apply(mcmc_samples, 2, function(x) c(mean = mean(x), sd = sd(x),\n                                                     lower_95 = quantile(x, 0.025),\n                                                     upper_95 = quantile(x, 0.975)))\n\n# Pretty table for MCMC summary\nsummary_mcmc_df &lt;- summary_mcmc %&gt;%\n  t() %&gt;%\n  as.data.frame() %&gt;%\n  round(3)\n\n# Display formatted table\nkable(summary_mcmc_df, caption = \"MCMC Parameter Estimates with 95% Credible Intervals\")\n\n\n\nMCMC Parameter Estimates with 95% Credible Intervals\n\n\n\nmean\nsd\nlower_95.2.5%\nupper_95.97.5%\n\n\n\n\nPrice\n-0.100\n0.006\n-0.109\n-0.086\n\n\nNetflix\n0.924\n0.113\n0.742\n1.157\n\n\nPrime\n0.488\n0.105\n0.311\n0.688\n\n\nAds\n-0.701\n0.075\n-0.863\n-0.568\n\n\n\n\n\nhint: Use N(0,5) priors for the betas on the binary variables, and a N(0,1) prior for the price beta.\n_hint: instead of calculating post=lik*prior, you can work in the log-space and calculate log-post = log-lik + log-prior (this should enable you to re-use your log-likelihood function from the MLE section just above)_\nhint: King Markov (in the video) use a candidate distribution of a coin flip to decide whether to move left or right among his islands. Unlike King Markov, we have 4 dimensions (because we have 4 betas) and our dimensions are continuous. So, use a multivariate normal distribution to pospose the next location for the algorithm to move to. I recommend a MNV(mu, Sigma) where mu=c(0,0,0,0) and sigma has diagonal values c(0.05, 0.05, 0.05, 0.005) and zeros on the off-diagonal. Since this MVN has no covariances, you can sample each dimension independently (so 4 univariate normals instead of 1 multivariate normal), where the first 3 univariate normals are N(0,0.05) and the last one if N(0,0.005).\n\n\nShow Code\n# Load necessary libraries\nlibrary(dplyr)\nlibrary(MASS)\nlibrary(knitr)\nlibrary(ggplot2)\n\n# Define log-prior function clearly (normal priors)\nlog_prior &lt;- function(beta) {\n  sum(dnorm(beta[1:3], mean = 0, sd = 5, log = TRUE)) + \n    dnorm(beta[4], mean = 0, sd = 1, log = TRUE)\n}\n\n# Robust Metropolis-Hastings MCMC sampler\nmcmc_sampler &lt;- function(initial_beta, data, n_iter = 11000, burn_in = 1000) {\n  n_params &lt;- length(initial_beta)\n  beta_current &lt;- initial_beta\n  log_posterior_current &lt;- -log_likelihood_mnl(beta_current, data) + log_prior(beta_current)\n\n  samples &lt;- matrix(NA, nrow = n_iter, ncol = n_params)\n  colnames(samples) &lt;- c(\"Price\", \"Netflix\", \"Prime\", \"Ads\")\n\n  for (i in 1:n_iter) {\n    # Correctly specified proposal distribution (standard deviations directly)\n    beta_proposed &lt;- beta_current + c(rnorm(3, mean = 0, sd = 0.05), rnorm(1, mean = 0, sd = 0.005))\n\n    # Calculate log-posterior for proposed\n    log_posterior_proposed &lt;- -log_likelihood_mnl(beta_proposed, data) + log_prior(beta_proposed)\n\n    # Compute acceptance probability safely\n    log_diff &lt;- log_posterior_proposed - log_posterior_current\n    accept_prob &lt;- min(1, exp(log_diff))\n\n    # Accept or reject the proposed sample\n    if (runif(1) &lt; accept_prob) {\n      beta_current &lt;- beta_proposed\n      log_posterior_current &lt;- log_posterior_proposed\n    }\n\n    # Save the current state\n    samples[i, ] &lt;- beta_current\n  }\n\n  # Remove burn-in samples\n  samples &lt;- samples[(burn_in + 1):n_iter, ]\n\n  return(samples)\n}\n\n# Run MCMC with corrected parameters\ninitial_beta &lt;- rep(0, 4)\nmcmc_samples &lt;- mcmc_sampler(initial_beta, prepared_conjoint_data)\n\n# Check output\nprint(head(mcmc_samples))\n\n\n           Price   Netflix     Prime        Ads\n[1,] -0.10703998 1.0191501 0.5119679 -0.1914770\n[2,] -0.10703998 1.0191501 0.5119679 -0.1914770\n[3,] -0.10703998 1.0191501 0.5119679 -0.1914770\n[4,] -0.08938323 1.0165321 0.5359181 -0.1885108\n[5,] -0.10129733 0.9032392 0.5377980 -0.1849112\n[6,] -0.10129733 0.9032392 0.5377980 -0.1849112\n\n\nShow Code\n# Trace plot for 'Price' parameter\nggplot(data.frame(iteration = 1:nrow(mcmc_samples), Price = mcmc_samples[, \"Price\"])) +\n  geom_line(aes(x = iteration, y = Price), color = \"blue\") +\n  labs(title = \"Trace Plot for Price Parameter\",\n       x = \"Iteration\", \n       y = \"Parameter Value\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow Code\n# Histogram for posterior distribution of 'Price' parameter\nggplot(data.frame(Price = mcmc_samples[, \"Price\"])) +\n  geom_histogram(aes(x = Price, y = after_stat(density)), bins = 30, fill = \"skyblue\", color = \"black\") +\n  geom_density(aes(x = Price), color = \"red\", linewidth = 1) +\n  labs(title = \"Posterior Distribution of Price Parameter\",\n       x = \"Price Parameter Value\",\n       y = \"Density\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow Code\n# Load libraries\nlibrary(dplyr)\nlibrary(knitr)\n\n# --- Verify MCMC samples exist ---\nif (!exists(\"mcmc_samples\")) stop(\"Error: 'mcmc_samples' not found. Please run the MCMC sampler first.\")\n\n# Compute Bayesian summary statistics explicitly\nbayesian_summary &lt;- apply(mcmc_samples, 2, function(x) {\n  c(\n    Mean = mean(x),\n    SD = sd(x),\n    Lower95 = quantile(x, 0.025),\n    Upper95 = quantile(x, 0.975)\n  )\n}) %&gt;%\n  t() %&gt;%\n  as.data.frame() %&gt;%\n  mutate(Method = \"Bayesian (MCMC)\", Parameter = rownames(.))\n\n# --- Verify MLE results exist ---\nif (!exists(\"result\")) stop(\"Error: 'result' object (MLE estimation results) not found. Please run the MLE first.\")\n\n# Compute MLE summary explicitly\nmle_estimates &lt;- result$par\nmle_se &lt;- sqrt(diag(solve(result$hessian)))\n\nmle_summary &lt;- data.frame(\n  Mean = mle_estimates,\n  SD = mle_se,\n  Lower95 = mle_estimates - 1.96 * mle_se,\n  Upper95 = mle_estimates + 1.96 * mle_se,\n  Method = \"MLE\",\n  Parameter = c(\"Price\", \"Netflix\", \"Prime\", \"Ads\")\n)\n\n# Combine Results Explicitly (fixed by explicitly specifying dplyr::select)\ncombined_results &lt;- bind_rows(bayesian_summary, mle_summary) %&gt;%\n  dplyr::select(Parameter, Method, Mean, SD, Lower95, Upper95) %&gt;%\n  mutate(across(c(Mean, SD, Lower95, Upper95), round, 3))\n\n# Explicit check before displaying the table\nif (exists(\"combined_results\")) {\n  knitr::kable(combined_results, caption = \"Comparison of Bayesian (MCMC) and MLE Estimates\")\n} else {\n  stop(\"Error: 'combined_results' still not created properly.\")\n}\n\n\n\nComparison of Bayesian (MCMC) and MLE Estimates\n\n\n\nParameter\nMethod\nMean\nSD\nLower95\nUpper95\n\n\n\n\nPrice\nPrice\nBayesian (MCMC)\n-0.097\n0.006\nNA\nNA\n\n\nNetflix\nNetflix\nBayesian (MCMC)\n0.909\n0.117\nNA\nNA\n\n\nPrime\nPrime\nBayesian (MCMC)\n0.463\n0.115\nNA\nNA\n\n\nAds\nAds\nBayesian (MCMC)\n-0.439\n0.132\nNA\nNA\n\n\n…5\nPrice\nMLE\n-0.099\n0.006\n-0.112\n-0.087\n\n\n…6\nNetflix\nMLE\n0.941\n0.111\n0.724\n1.159\n\n\n…7\nPrime\nMLE\n0.502\n0.111\n0.284\n0.719\n\n\n…8\nAds\nMLE\n-0.732\n0.088\n-0.904\n-0.560"
  },
  {
    "objectID": "blog/project5/hw3_questions.html#discussion",
    "href": "blog/project5/hw3_questions.html#discussion",
    "title": "Multinomial Logit Model",
    "section": "6. Discussion",
    "text": "6. Discussion\n\nObservations about Parameter Estimates:\n\nPositive Parameter for Netflix (β Netflix): A positive value for β Netflix suggests consumers have a stronger preference for Netflix relative to the baseline brand (Hulu, in this case).\nComparison of Netflix vs. Prime (β Netflix &gt;β Prime): If β Netflix &gt; β Prime, it indicates consumers generally prefer Netflix over Amazon Prime, holding other factors constant. This ranking makes intuitive sense if consumers perceive Netflix to offer greater value, better content, or higher brand prestige.\nNegative Price Parameter (β Price): A negative value for β Price implies that as price increases, consumer utility decreases, making a consumer less likely to select that streaming service. This aligns with typical economic theory where higher prices reduce consumer utility and demand.\n\n\n\nEconomic Interpretation:\n\nBrand Preferences: β Netflix &gt;β Prime &gt;0 implies a clear hierarchy in consumer preferences among streaming services. Netflix is perceived as most desirable, followed by Prime, with Hulu as the baseline least preferred.\nPrice Sensitivity: The negative price sensitivity (β Price &lt;0) is entirely sensible and consistent with standard consumer behavior—consumers prefer lower prices.\n\nThus, even if you did not simulate the data yourself, these parameter estimates are intuitive and economically meaningful, reflecting realistic consumer behavior patterns in the streaming services market.\n\n\n1. Conceptual Changes (High Level):\nIn a standard MNL model, all consumers share the same set of parameters β. A hierarchical (multi-level) approach recognizes that each consumer might have individual-specific parameters (β i), drawn from a common distribution. The hierarchical structure is: Level 1 (Individual choice): \\(U_{ij}=x_j'\\beta+\\epsilon_{ij}\\) Level 2 (Population distribution of preferences): \\[ beta_i \\sim N(\\bar{\\beta}, \\Sigma) \\]\n–&gt; Level 1 captures within-individual variation (choices made by consumers). –&gt; Level 2 captures between-individual variation (differences across consumers).\n\n\n2. Simulating Hierarchical Data:\nTo simulate hierarchical data, you would:\nStep 1: Draw each consumer’s individual preference parameters from a multivariate normal distribution: \\(\\beta_i \\sim N(\\bar{\\beta}, \\Sigma)\\) Step 2: For each consumer, simulate their choices based on these individualized preferences: \\[\nU_{ij} = x_j'\\beta_i + \\varepsilon_{ij}, \\quad \\varepsilon_{ij}\\sim \\text{Gumbel}(0,1)\n\\]\n\n\nNote\nset.seed(123)\nn_consumers &lt;- 100\nmean_beta &lt;- c(-0.1, 1.0, 0.5, -0.8)  # mean parameters at population level\nsigma_beta &lt;- diag(c(0.05, 0.5, 0.5, 0.3))  # variance-covariance (individual differences)\n\n# Draw individual betas\nindividual_betas &lt;- MASS::mvrnorm(n_consumers, mean_beta, sigma_beta)\n\n\n\n\n3. Estimating a Hierarchical Model:\nEstimation of hierarchical models typically involves Bayesian approaches using Markov Chain Monte Carlo (MCMC) or Maximum Simulated Likelihood (MSL):\n\nBayesian (Hierarchical Bayesian) Approach:\n\n\nUse MCMC techniques like Gibbs sampling or Metropolis-Hastings, which estimate individual-specific parameters as well as population-level parameters.\nPriors are assigned at the population level (hyperparameters).\n\n\nMaximum Simulated Likelihood (MSL) Approach:\n\n\nUse simulation methods to integrate over the distribution of individual preferences.\nMethods like Mixed Logit or Random Parameter Logit are commonly applied.\n\n\n\n4. Practical Steps for Implementation:\nExtend your likelihood function to incorporate random parameters (individual-level β i s). Use specialized software/libraries: 1) R packages: bayesm, rstan, brms, or mlogit. 2) Python packages: PyMC, Stan/PyStan, or biogeme."
  },
  {
    "objectID": "hw3_questions.html",
    "href": "hw3_questions.html",
    "title": "Multinomial Logit Model",
    "section": "",
    "text": "This assignment expores two methods for estimating the MNL model: (1) via Maximum Likelihood, and (2) via a Bayesian approach using a Metropolis-Hastings MCMC algorithm."
  },
  {
    "objectID": "hw3_questions.html#likelihood-for-the-multi-nomial-logit-mnl-model",
    "href": "hw3_questions.html#likelihood-for-the-multi-nomial-logit-mnl-model",
    "title": "Multinomial Logit Model",
    "section": "1. Likelihood for the Multi-nomial Logit (MNL) Model",
    "text": "1. Likelihood for the Multi-nomial Logit (MNL) Model\nSuppose we have \\(i=1,\\ldots,n\\) consumers who each select exactly one product \\(j\\) from a set of \\(J\\) products. The outcome variable is the identity of the product chosen \\(y_i \\in \\{1, \\ldots, J\\}\\) or equivalently a vector of \\(J-1\\) zeros and \\(1\\) one, where the \\(1\\) indicates the selected product. For example, if the third product was chosen out of 3 products, then either \\(y=3\\) or \\(y=(0,0,1)\\) depending on how we want to represent it. Suppose also that we have a vector of data on each product \\(x_j\\) (eg, brand, price, etc.).\nWe model the consumer’s decision as the selection of the product that provides the most utility, and we’ll specify the utility function as a linear function of the product characteristics:\n\\[ U_{ij} = x_j'\\beta + \\epsilon_{ij} \\]\nwhere \\(\\epsilon_{ij}\\) is an i.i.d. extreme value error term.\nThe choice of the i.i.d. extreme value error term leads to a closed-form expression for the probability that consumer \\(i\\) chooses product \\(j\\):\n\\[ \\mathbb{P}_i(j) = \\frac{e^{x_j'\\beta}}{\\sum_{k=1}^Je^{x_k'\\beta}} \\]\nFor example, if there are 3 products, the probability that consumer \\(i\\) chooses product 3 is:\n\\[ \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{e^{x_1'\\beta} + e^{x_2'\\beta} + e^{x_3'\\beta}} \\]\nA clever way to write the individual likelihood function for consumer \\(i\\) is the product of the \\(J\\) probabilities, each raised to the power of an indicator variable (\\(\\delta_{ij}\\)) that indicates the chosen product:\n\\[ L_i(\\beta) = \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} = \\mathbb{P}_i(1)^{\\delta_{i1}} \\times \\ldots \\times \\mathbb{P}_i(J)^{\\delta_{iJ}}\\]\nNotice that if the consumer selected product \\(j=3\\), then \\(\\delta_{i3}=1\\) while \\(\\delta_{i1}=\\delta_{i2}=0\\) and the likelihood is:\n\\[ L_i(\\beta) = \\mathbb{P}_i(1)^0 \\times \\mathbb{P}_i(2)^0 \\times \\mathbb{P}_i(3)^1 = \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{\\sum_{k=1}^3e^{x_k'\\beta}} \\]\nThe joint likelihood (across all consumers) is the product of the \\(n\\) individual likelihoods:\n\\[ L_n(\\beta) = \\prod_{i=1}^n L_i(\\beta) = \\prod_{i=1}^n \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} \\]\nAnd the joint log-likelihood function is:\n\\[ \\ell_n(\\beta) = \\sum_{i=1}^n \\sum_{j=1}^J \\delta_{ij} \\log(\\mathbb{P}_i(j)) \\]"
  },
  {
    "objectID": "hw3_questions.html#simulate-conjoint-data",
    "href": "hw3_questions.html#simulate-conjoint-data",
    "title": "Multinomial Logit Model",
    "section": "2. Simulate Conjoint Data",
    "text": "2. Simulate Conjoint Data\nWe will simulate data from a conjoint experiment about video content streaming services. We elect to simulate 100 respondents, each completing 10 choice tasks, where they choose from three alternatives per task. For simplicity, there is not a “no choice” option; each simulated respondent must select one of the 3 alternatives.\nEach alternative is a hypothetical streaming offer consistent of three attributes: (1) brand is either Netflix, Amazon Prime, or Hulu; (2) ads can either be part of the experience, or it can be ad-free, and (3) price per month ranges from $4 to $32 in increments of $4.\nThe part-worths (ie, preference weights or beta parameters) for the attribute levels will be 1.0 for Netflix, 0.5 for Amazon Prime (with 0 for Hulu as the reference brand); -0.8 for included adverstisements (0 for ad-free); and -0.1*price so that utility to consumer \\(i\\) for hypothethical streaming service \\(j\\) is\n\\[\nu_{ij} = (1 \\times Netflix_j) + (0.5 \\times Prime_j) + (-0.8*Ads_j) - 0.1\\times Price_j + \\varepsilon_{ij}\n\\]\nwhere the variables are binary indicators and \\(\\varepsilon\\) is Type 1 Extreme Value (ie, Gumble) distributed.\nThe following code provides the simulation of the conjoint data.\n\n\n\n\n\n\nNote\n\n\n\n\n\n\n# set seed for reproducibility\nset.seed(123)\n\n# define attributes\nbrand &lt;- c(\"N\", \"P\", \"H\") # Netflix, Prime, Hulu\nad &lt;- c(\"Yes\", \"No\")\nprice &lt;- seq(8, 32, by=4)\n\n# generate all possible profiles\nprofiles &lt;- expand.grid(\n    brand = brand,\n    ad = ad,\n    price = price\n)\nm &lt;- nrow(profiles)\n\n# assign part-worth utilities (true parameters)\nb_util &lt;- c(N = 1.0, P = 0.5, H = 0)\na_util &lt;- c(Yes = -0.8, No = 0.0)\np_util &lt;- function(p) -0.1 * p\n\n# number of respondents, choice tasks, and alternatives per task\nn_peeps &lt;- 100\nn_tasks &lt;- 10\nn_alts &lt;- 3\n\n# function to simulate one respondent’s data\nsim_one &lt;- function(id) {\n  \n    datlist &lt;- list()\n    \n    # loop over choice tasks\n    for (t in 1:n_tasks) {\n        \n        # randomly sample 3 alts (better practice would be to use a design)\n        dat &lt;- cbind(resp=id, task=t, profiles[sample(m, size=n_alts), ])\n        \n        # compute deterministic portion of utility\n        dat$v &lt;- b_util[dat$brand] + a_util[dat$ad] + p_util(dat$price) |&gt; round(10)\n        \n        # add Gumbel noise (Type I extreme value)\n        dat$e &lt;- -log(-log(runif(n_alts)))\n        dat$u &lt;- dat$v + dat$e\n        \n        # identify chosen alternative\n        dat$choice &lt;- as.integer(dat$u == max(dat$u))\n        \n        # store task\n        datlist[[t]] &lt;- dat\n    }\n    \n    # combine all tasks for one respondent\n    do.call(rbind, datlist)\n}\n\n# simulate data for all respondents\nconjoint_data &lt;- do.call(rbind, lapply(1:n_peeps, sim_one))\n\n# remove values unobservable to the researcher\nconjoint_data &lt;- conjoint_data[ , c(\"resp\", \"task\", \"brand\", \"ad\", \"price\", \"choice\")]\n\n# clean up\nrm(list=setdiff(ls(), \"conjoint_data\"))"
  },
  {
    "objectID": "hw3_questions.html#preparing-the-data-for-estimation",
    "href": "hw3_questions.html#preparing-the-data-for-estimation",
    "title": "Multinomial Logit Model",
    "section": "3. Preparing the Data for Estimation",
    "text": "3. Preparing the Data for Estimation\nThe “hard part” of the MNL likelihood function is organizing the data, as we need to keep track of 3 dimensions (consumer \\(i\\), covariate \\(k\\), and product \\(j\\)) instead of the typical 2 dimensions for cross-sectional regression models (consumer \\(i\\) and covariate \\(k\\)). The fact that each task for each respondent has the same number of alternatives (3) helps. In addition, we need to convert the categorical variables for brand and ads into binary variables.\ntodo: reshape and prep the data"
  },
  {
    "objectID": "hw3_questions.html#estimation-via-maximum-likelihood",
    "href": "hw3_questions.html#estimation-via-maximum-likelihood",
    "title": "Multinomial Logit Model",
    "section": "4. Estimation via Maximum Likelihood",
    "text": "4. Estimation via Maximum Likelihood\ntodo: Code up the log-likelihood function.\ntodo: Use optim() in R or scipy.optimize() in Python to find the MLEs for the 4 parameters (\\(\\beta_\\text{netflix}\\), \\(\\beta_\\text{prime}\\), \\(\\beta_\\text{ads}\\), \\(\\beta_\\text{price}\\)), as well as their standard errors (from the Hessian). For each parameter construct a 95% confidence interval."
  },
  {
    "objectID": "hw3_questions.html#estimation-via-bayesian-methods",
    "href": "hw3_questions.html#estimation-via-bayesian-methods",
    "title": "Multinomial Logit Model",
    "section": "5. Estimation via Bayesian Methods",
    "text": "5. Estimation via Bayesian Methods\ntodo: code up a metropolis-hasting MCMC sampler of the posterior distribution. Take 11,000 steps and throw away the first 1,000, retaining the subsequent 10,000.\nhint: Use N(0,5) priors for the betas on the binary variables, and a N(0,1) prior for the price beta.\n_hint: instead of calculating post=lik*prior, you can work in the log-space and calculate log-post = log-lik + log-prior (this should enable you to re-use your log-likelihood function from the MLE section just above)_\nhint: King Markov (in the video) use a candidate distribution of a coin flip to decide whether to move left or right among his islands. Unlike King Markov, we have 4 dimensions (because we have 4 betas) and our dimensions are continuous. So, use a multivariate normal distribution to pospose the next location for the algorithm to move to. I recommend a MNV(mu, Sigma) where mu=c(0,0,0,0) and sigma has diagonal values c(0.05, 0.05, 0.05, 0.005) and zeros on the off-diagonal. Since this MVN has no covariances, you can sample each dimension independently (so 4 univariate normals instead of 1 multivariate normal), where the first 3 univariate normals are N(0,0.05) and the last one if N(0,0.005).\ntodo: for at least one of the 4 parameters, show the trace plot of the algorithm, as well as the histogram of the posterior distribution.\ntodo: report the 4 posterior means, standard deviations, and 95% credible intervals and compare them to your results from the Maximum Likelihood approach."
  },
  {
    "objectID": "hw3_questions.html#discussion",
    "href": "hw3_questions.html#discussion",
    "title": "Multinomial Logit Model",
    "section": "6. Discussion",
    "text": "6. Discussion\ntodo: Suppose you did not simulate the data. What do you observe about the parameter estimates? What does \\(\\beta_\\text{Netflix} &gt; \\beta_\\text{Prime}\\) mean? Does it make sense that \\(\\beta_\\text{price}\\) is negative?\ntodo: At a high level, discuss what change you would need to make in order to simulate data from — and estimate the parameters of — a multi-level (aka random-parameter or hierarchical) model. This is the model we use to analyze “real world” conjoint data."
  },
  {
    "objectID": "blog/project5/hw3_questions.html#observations-about-parameter-estimates",
    "href": "blog/project5/hw3_questions.html#observations-about-parameter-estimates",
    "title": "Multinomial Logit Model",
    "section": "Observations about Parameter Estimates:",
    "text": "Observations about Parameter Estimates:\n\nPositive Parameter for Netflix (β Netflix): A positive value for β Netflix suggests consumers have a stronger preference for Netflix relative to the baseline brand (Hulu, in this case).\nComparison of Netflix vs. Prime (β Netflix &gt;β Prime): If β Netflix &gt; β Prime, it indicates consumers generally prefer Netflix over Amazon Prime, holding other factors constant. This ranking makes intuitive sense if consumers perceive Netflix to offer greater value, better content, or higher brand prestige.\nNegative Price Parameter (β Price): A negative value for β Price implies that as price increases, consumer utility decreases, making a consumer less likely to select that streaming service. This aligns with typical economic theory where higher prices reduce consumer utility and demand."
  },
  {
    "objectID": "blog/project5/hw3_questions.html#economic-interpretation",
    "href": "blog/project5/hw3_questions.html#economic-interpretation",
    "title": "Multinomial Logit Model",
    "section": "Economic Interpretation:",
    "text": "Economic Interpretation:\n\nBrand Preferences: β Netflix &gt;β Prime &gt;0 implies a clear hierarchy in consumer preferences among streaming services. Netflix is perceived as most desirable, followed by Prime, with Hulu as the baseline least preferred.\nPrice Sensitivity: The negative price sensitivity (β Price &lt;0) is entirely sensible and consistent with standard consumer behavior—consumers prefer lower prices.\n\nThus, even if you did not simulate the data yourself, these parameter estimates are intuitive and economically meaningful, reflecting realistic consumer behavior patterns in the streaming services market.\ntodo: At a high level, discuss what change you would need to make in order to simulate data from — and estimate the parameters of — a multi-level (aka random-parameter or hierarchical) model. This is the model we use to analyze “real world” conjoint data."
  },
  {
    "objectID": "blog/project6/hw4_questions.html",
    "href": "blog/project6/hw4_questions.html",
    "title": "Machine Learning",
    "section": "",
    "text": "Click to view code\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\n\n# Load data\npenguins = pd.read_csv('palmer_penguins.csv')\n\n# Select correct columns based on actual names\nX = penguins[['bill_length_mm', 'flipper_length_mm']].dropna().values\n\n# Verify data loaded correctly\nprint(X[:5])\n\n# Custom K-means implementation\ndef custom_kmeans(X, k, max_iter=10):\n    np.random.seed(42)\n    centroids = X[np.random.choice(len(X), k, replace=False)]\n    history = [centroids.copy()]\n\n    for _ in range(max_iter):\n        distances = np.linalg.norm(X[:, np.newaxis] - centroids, axis=2)\n        clusters = np.argmin(distances, axis=1)\n\n        new_centroids = np.array([X[clusters == i].mean(axis=0) for i in range(k)])\n        history.append(new_centroids.copy())\n\n        if np.allclose(centroids, new_centroids):\n            break\n\n        centroids = new_centroids\n\n    return centroids, clusters, history\n\n# Run custom K-means\nk = 3\ncentroids, clusters, history = custom_kmeans(X, k)\n\n# Plot iterations\nfor i, centroid_iter in enumerate(history):\n    plt.figure(figsize=(6, 4))\n    plt.scatter(X[:, 0], X[:, 1], c='gray', alpha=0.5)\n    plt.scatter(centroid_iter[:, 0], centroid_iter[:, 1], c='red', s=100, label='Centroids')\n    plt.title(f'Iteration {i}')\n    plt.xlabel('Bill Length (mm)')\n    plt.ylabel('Flipper Length (mm)')\n    plt.legend()\n    plt.show()\n\n# Built-in KMeans comparison\nbuiltin_kmeans = KMeans(n_clusters=3, random_state=42).fit(X)\n\nplt.figure(figsize=(6, 4))\nplt.scatter(X[:, 0], X[:, 1], c=builtin_kmeans.labels_, cmap='viridis', alpha=0.5)\nplt.scatter(builtin_kmeans.cluster_centers_[:, 0], builtin_kmeans.cluster_centers_[:, 1],\n            c='red', s=100, marker='x')\nplt.title('Built-in KMeans Results')\nplt.xlabel('Bill Length (mm)')\nplt.ylabel('Flipper Length (mm)')\nplt.show()\n\n\n[[ 39.1 181. ]\n [ 39.5 186. ]\n [ 40.3 195. ]\n [ 36.7 193. ]\n [ 39.3 190. ]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\n# Load data\npenguins = pd.read_csv('palmer_penguins.csv')\nX = penguins[['bill_length_mm', 'flipper_length_mm']].dropna().values\n\nwcss = []\nsilhouette_scores = []\nK_range = range(2, 8)\n\n# Calculate metrics for different cluster sizes\nfor k in K_range:\n    kmeans = KMeans(n_clusters=k, random_state=42)\n    labels = kmeans.fit_predict(X)\n    wcss.append(kmeans.inertia_)\n    silhouette_scores.append(silhouette_score(X, labels))\n\n# Plot Within-Cluster-Sum-of-Squares (WCSS)\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(K_range, wcss, marker='o')\nplt.title('Within-Cluster Sum of Squares (Elbow Method)')\nplt.xlabel('Number of clusters (K)')\nplt.ylabel('WCSS')\n\n# Plot Silhouette scores\nplt.subplot(1, 2, 2)\nplt.plot(K_range, silhouette_scores, marker='o', color='green')\nplt.title('Silhouette Scores')\nplt.xlabel('Number of clusters (K)')\nplt.ylabel('Silhouette Score')\n\nplt.tight_layout()\nplt.show()\n\n# Identify the best K\noptimal_k_silhouette = K_range[np.argmax(silhouette_scores)]\noptimal_k_wcss = 3  # Usually visually identified from the elbow method\n\nprint(f\"Optimal K based on silhouette score: {optimal_k_silhouette}\")\nprint(f\"Optimal K based on elbow (WCSS): {optimal_k_wcss}\")\n\n\n\n\n\n\n\n\n\nOptimal K based on silhouette score: 2\nOptimal K based on elbow (WCSS): 3"
  },
  {
    "objectID": "blog/project6/hw4_questions.html#a.-k-means",
    "href": "blog/project6/hw4_questions.html#a.-k-means",
    "title": "Machine Learning",
    "section": "",
    "text": "Click to view code\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\n\n# Load data\npenguins = pd.read_csv('palmer_penguins.csv')\n\n# Select correct columns based on actual names\nX = penguins[['bill_length_mm', 'flipper_length_mm']].dropna().values\n\n# Verify data loaded correctly\nprint(X[:5])\n\n# Custom K-means implementation\ndef custom_kmeans(X, k, max_iter=10):\n    np.random.seed(42)\n    centroids = X[np.random.choice(len(X), k, replace=False)]\n    history = [centroids.copy()]\n\n    for _ in range(max_iter):\n        distances = np.linalg.norm(X[:, np.newaxis] - centroids, axis=2)\n        clusters = np.argmin(distances, axis=1)\n\n        new_centroids = np.array([X[clusters == i].mean(axis=0) for i in range(k)])\n        history.append(new_centroids.copy())\n\n        if np.allclose(centroids, new_centroids):\n            break\n\n        centroids = new_centroids\n\n    return centroids, clusters, history\n\n# Run custom K-means\nk = 3\ncentroids, clusters, history = custom_kmeans(X, k)\n\n# Plot iterations\nfor i, centroid_iter in enumerate(history):\n    plt.figure(figsize=(6, 4))\n    plt.scatter(X[:, 0], X[:, 1], c='gray', alpha=0.5)\n    plt.scatter(centroid_iter[:, 0], centroid_iter[:, 1], c='red', s=100, label='Centroids')\n    plt.title(f'Iteration {i}')\n    plt.xlabel('Bill Length (mm)')\n    plt.ylabel('Flipper Length (mm)')\n    plt.legend()\n    plt.show()\n\n# Built-in KMeans comparison\nbuiltin_kmeans = KMeans(n_clusters=3, random_state=42).fit(X)\n\nplt.figure(figsize=(6, 4))\nplt.scatter(X[:, 0], X[:, 1], c=builtin_kmeans.labels_, cmap='viridis', alpha=0.5)\nplt.scatter(builtin_kmeans.cluster_centers_[:, 0], builtin_kmeans.cluster_centers_[:, 1],\n            c='red', s=100, marker='x')\nplt.title('Built-in KMeans Results')\nplt.xlabel('Bill Length (mm)')\nplt.ylabel('Flipper Length (mm)')\nplt.show()\n\n\n[[ 39.1 181. ]\n [ 39.5 186. ]\n [ 40.3 195. ]\n [ 36.7 193. ]\n [ 39.3 190. ]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\n# Load data\npenguins = pd.read_csv('palmer_penguins.csv')\nX = penguins[['bill_length_mm', 'flipper_length_mm']].dropna().values\n\nwcss = []\nsilhouette_scores = []\nK_range = range(2, 8)\n\n# Calculate metrics for different cluster sizes\nfor k in K_range:\n    kmeans = KMeans(n_clusters=k, random_state=42)\n    labels = kmeans.fit_predict(X)\n    wcss.append(kmeans.inertia_)\n    silhouette_scores.append(silhouette_score(X, labels))\n\n# Plot Within-Cluster-Sum-of-Squares (WCSS)\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(K_range, wcss, marker='o')\nplt.title('Within-Cluster Sum of Squares (Elbow Method)')\nplt.xlabel('Number of clusters (K)')\nplt.ylabel('WCSS')\n\n# Plot Silhouette scores\nplt.subplot(1, 2, 2)\nplt.plot(K_range, silhouette_scores, marker='o', color='green')\nplt.title('Silhouette Scores')\nplt.xlabel('Number of clusters (K)')\nplt.ylabel('Silhouette Score')\n\nplt.tight_layout()\nplt.show()\n\n# Identify the best K\noptimal_k_silhouette = K_range[np.argmax(silhouette_scores)]\noptimal_k_wcss = 3  # Usually visually identified from the elbow method\n\nprint(f\"Optimal K based on silhouette score: {optimal_k_silhouette}\")\nprint(f\"Optimal K based on elbow (WCSS): {optimal_k_wcss}\")\n\n\n\n\n\n\n\n\n\nOptimal K based on silhouette score: 2\nOptimal K based on elbow (WCSS): 3"
  },
  {
    "objectID": "blog/project6/hw4_questions.html#b.-latent-class-mnl",
    "href": "blog/project6/hw4_questions.html#b.-latent-class-mnl",
    "title": "Machine Learning",
    "section": "1b. Latent-Class MNL",
    "text": "1b. Latent-Class MNL\ntodo: Use the Yogurt dataset to estimate a latent-class MNL model. This model was formally introduced in the paper by Kamakura & Russell (1989); you may want to read or reference page 2 of the pdf, which is described in the class slides, session 4, slides 56-57.\nThe data provides anonymized consumer identifiers (id), a vector indicating the chosen product (y1:y4), a vector indicating if any products were “featured” in the store as a form of advertising (f1:f4), and the products’ prices in price-per-ounce (p1:p4). For example, consumer 1 purchased yogurt 4 at a price of 0.079/oz and none of the yogurts were featured/advertised at the time of consumer 1’s purchase. Consumers 2 through 7 each bought yogurt 2, etc. You may want to reshape the data from its current “wide” format into a “long” format.\ntodo: Fit the standard MNL model on these data. Then fit the latent-class MNL on these data separately for 2, 3, 4, and 5 latent classes.\ntodo: How many classes are suggested by the \\(BIC = -2*\\ell_n  + k*log(n)\\)? (where \\(\\ell_n\\) is the log-likelihood, \\(n\\) is the sample size, and \\(k\\) is the number of parameters.) The Bayesian-Schwarz Information Criterion link is a metric that assess the benefit of a better log likelihood at the expense of additional parameters to estimate – akin to the adjusted R-squared for the linear regression model. Note, that a lower BIC indicates a better model fit, accounting for the number of parameters in the model.\ntodo: compare the parameter estimates between (1) the aggregate MNL, and (2) the latent-class MNL with the number of classes suggested by the BIC."
  },
  {
    "objectID": "blog/project6/hw4_questions.html#a.-k-nearest-neighbors",
    "href": "blog/project6/hw4_questions.html#a.-k-nearest-neighbors",
    "title": "Machine Learning",
    "section": "2a. K Nearest Neighbors",
    "text": "2a. K Nearest Neighbors\n\n\nClick to view code\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# Generate synthetic data\nn = 100\nx1 = np.random.uniform(-3, 3, n)\nx2 = np.random.uniform(-3, 3, n)\n\n# Create boundary\nboundary = np.sin(4 * x1) + x1\n\n# Generate binary outcome based on boundary\ny = (x2 &gt; boundary).astype(int)\n\n# Compile data into a DataFrame\ndat = pd.DataFrame({'x1': x1, 'x2': x2, 'y': y})\n\n# Plot the data with boundary\nplt.figure(figsize=(8, 6))\nplt.scatter(dat.x1, dat.x2, c=dat.y, cmap='coolwarm', edgecolor='k', alpha=0.7)\nplt.title('Synthetic Dataset with Wiggly Boundary')\nplt.xlabel('x1')\nplt.ylabel('x2')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# Generate synthetic data\nn = 100\nx1 = np.random.uniform(-3, 3, n)\nx2 = np.random.uniform(-3, 3, n)\n\n# Create boundary\nboundary = np.sin(4 * x1) + x1\n\n# Generate binary outcome based on boundary\ny = (x2 &gt; boundary).astype(int)\n\n# Compile data into a DataFrame\ndat = pd.DataFrame({'x1': x1, 'x2': x2, 'y': y})\n\n# Plot the data and boundary\nplt.figure(figsize=(8, 6))\nscatter = plt.scatter(dat.x1, dat.x2, c=dat.y, cmap='coolwarm', edgecolor='k', alpha=0.7, label='Data points')\n\n# Draw the wiggly boundary\nx_boundary = np.linspace(-3, 3, 400)\ny_boundary = np.sin(4 * x_boundary) + x_boundary\nplt.plot(x_boundary, y_boundary, color='black', linewidth=2, label='Boundary')\n\nplt.title('Synthetic Dataset with Wiggly Boundary')\nplt.xlabel('x1')\nplt.ylabel('x2')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Function to generate synthetic data\ndef generate_data(seed, n=100):\n    np.random.seed(seed)\n    x1 = np.random.uniform(-3, 3, n)\n    x2 = np.random.uniform(-3, 3, n)\n    boundary = np.sin(4 * x1) + x1\n    y = (x2 &gt; boundary).astype(int)\n    return pd.DataFrame({'x1': x1, 'x2': x2, 'y': y})\n\n# Generate training dataset\ndat_train = generate_data(seed=42)\n\n# Generate test dataset\ndat_test = generate_data(seed=99)\n\n# Plot the training dataset and boundary\nplt.figure(figsize=(8, 6))\nplt.scatter(dat_train.x1, dat_train.x2, c=dat_train.y, cmap='coolwarm', edgecolor='k', alpha=0.7, label='Training Data')\n\n# Draw the wiggly boundary\nx_boundary = np.linspace(-3, 3, 400)\ny_boundary = np.sin(4 * x_boundary) + x_boundary\nplt.plot(x_boundary, y_boundary, color='black', linewidth=2, label='Boundary')\n\nplt.title('Training Dataset with Wiggly Boundary')\nplt.xlabel('x1')\nplt.ylabel('x2')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Optionally plot the test dataset\nplt.figure(figsize=(8, 6))\nplt.scatter(dat_test.x1, dat_test.x2, c=dat_test.y, cmap='coolwarm', edgecolor='k', alpha=0.7, label='Test Data')\nplt.plot(x_boundary, y_boundary, color='black', linewidth=2, label='Boundary')\n\nplt.title('Test Dataset with Wiggly Boundary')\nplt.xlabel('x1')\nplt.ylabel('x2')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Function to generate synthetic data\ndef generate_data(seed, n=100):\n    np.random.seed(seed)\n    x1 = np.random.uniform(-3, 3, n)\n    x2 = np.random.uniform(-3, 3, n)\n    boundary = np.sin(4 * x1) + x1\n    y = (x2 &gt; boundary).astype(int)\n    return pd.DataFrame({'x1': x1, 'x2': x2, 'y': y})\n\n# Generate training dataset\ndat_train = generate_data(seed=42)\nX_train = dat_train[['x1', 'x2']].values\ny_train = dat_train['y'].values\n\n# Generate test dataset\ndat_test = generate_data(seed=99)\nX_test = dat_test[['x1', 'x2']].values\ny_test = dat_test['y'].values\n\n# KNN implemented manually\ndef knn_predict(X_train, y_train, X_test, k=5):\n    predictions = []\n    for test_point in X_test:\n        distances = np.linalg.norm(X_train - test_point, axis=1)\n        nearest_indices = np.argsort(distances)[:k]\n        nearest_labels = y_train[nearest_indices]\n        prediction = np.bincount(nearest_labels).argmax()\n        predictions.append(prediction)\n    return np.array(predictions)\n\n# Predict manually\ny_pred_manual = knn_predict(X_train, y_train, X_test, k=5)\n\n# Verify using scikit-learn\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\ny_pred_sklearn = knn.predict(X_test)\n\n# Check if predictions match\naccuracy_manual = np.mean(y_pred_manual == y_test)\naccuracy_sklearn = np.mean(y_pred_sklearn == y_test)\n\nprint(f\"Accuracy (Manual KNN): {accuracy_manual:.2f}\")\nprint(f\"Accuracy (sklearn KNN): {accuracy_sklearn:.2f}\")\n\n\nAccuracy (Manual KNN): 0.90\nAccuracy (sklearn KNN): 0.90\n\n\n\n\nClick to view code\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Function to generate synthetic data\ndef generate_data(seed, n=100):\n    np.random.seed(seed)\n    x1 = np.random.uniform(-3, 3, n)\n    x2 = np.random.uniform(-3, 3, n)\n    boundary = np.sin(4 * x1) + x1\n    y = (x2 &gt; boundary).astype(int)\n    return pd.DataFrame({'x1': x1, 'x2': x2, 'y': y})\n\n# Generate training dataset\ndat_train = generate_data(seed=42)\nX_train = dat_train[['x1', 'x2']].values\ny_train = dat_train['y'].values\n\n# Generate test dataset\ndat_test = generate_data(seed=99)\nX_test = dat_test[['x1', 'x2']].values\ny_test = dat_test['y'].values\n\n# KNN implemented manually\ndef knn_predict(X_train, y_train, X_test, k=5):\n    predictions = []\n    for test_point in X_test:\n        distances = np.linalg.norm(X_train - test_point, axis=1)\n        nearest_indices = np.argsort(distances)[:k]\n        nearest_labels = y_train[nearest_indices]\n        prediction = np.bincount(nearest_labels).argmax()\n        predictions.append(prediction)\n    return np.array(predictions)\n\n# Calculate accuracy for k=1 to k=30\naccuracies = []\nk_values = range(1, 31)\nfor k in k_values:\n    y_pred = knn_predict(X_train, y_train, X_test, k=k)\n    accuracy = np.mean(y_pred == y_test)\n    accuracies.append(accuracy)\n\n# Plot accuracy vs k\nplt.figure(figsize=(10, 6))\nplt.plot(k_values, accuracies, marker='o')\nplt.title('KNN Accuracy for Different k Values')\nplt.xlabel('k')\nplt.ylabel('Accuracy')\nplt.grid(True)\nplt.show()\n\n# Optimal k\noptimal_k = k_values[np.argmax(accuracies)]\nprint(f\"Optimal k: {optimal_k} with accuracy: {max(accuracies):.2f}\")\n\n\n\n\n\n\n\n\n\nOptimal k: 1 with accuracy: 0.92"
  },
  {
    "objectID": "blog/project6/hw4_questions.html#b.-key-drivers-analysis",
    "href": "blog/project6/hw4_questions.html#b.-key-drivers-analysis",
    "title": "Machine Learning",
    "section": "2b. Key Drivers Analysis",
    "text": "2b. Key Drivers Analysis\ntodo: replicate the table on slide 75 of the session 5 slides. Specifically, using the dataset provided in the file data_for_drivers_analysis.csv, calculate: pearson correlations, standardized regression coefficients, “usefulness”, Shapley values for a linear regression, Johnson’s relative weights, and the mean decrease in the gini coefficient from a random forest. You may use packages built into R or Python; you do not need to perform these calculations “by hand.”\nIf you want a challenge, add additional measures to the table such as the importance scores from XGBoost, from a Neural Network, or from any additional method that measures the importance of variables."
  }
]